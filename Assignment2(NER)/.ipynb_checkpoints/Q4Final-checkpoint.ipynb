{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8813362-2600-4d55-8322-724f8817ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_of_f1_score=0\n",
    "\n",
    "def calculate(true_labels, predicted_labels,cls):\n",
    "    TP = 0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for true_sent, pred_sent in zip(true_labels, predicted_labels):\n",
    "        for true, pred in zip(true_sent, pred_sent):\n",
    "             # just continue\n",
    "            if true != cls and pred != cls:\n",
    "                continue\n",
    "            # Increment true positives\n",
    "            elif true == pred and true == cls:\n",
    "                TP=TP+1\n",
    "            # Increment false positives\n",
    "            elif pred==cls and true != cls:\n",
    "                FP=FP+1\n",
    "            # Increment false negatives\n",
    "            elif pred!=cls and true == cls:\n",
    "                FN=FN+1\n",
    "    print(\"for class::\",cls)\n",
    "    print(\"False Positive::\",FP)\n",
    "    print(\"True Positive::\",TP)\n",
    "    print(\"False Negative::\",FN)\n",
    "    if (TP+FP)!=0:\n",
    "        precision=TP/(TP+FP)\n",
    "    else:\n",
    "        precision=0\n",
    "    if (TP+FN)!=0:\n",
    "        Recall=TP/(TP+FN)\n",
    "    else:\n",
    "        Recall=0\n",
    "    \n",
    "    print(\"Precision:-\",precision)\n",
    "    print(\"Recall:-\",Recall)\n",
    "    f1=0\n",
    "    global sum_of_f1_score\n",
    "    if((precision+Recall)!=0):\n",
    "            f1=2*precision*Recall/(precision+Recall)\n",
    "\n",
    "    print(\"f1:-\",f1)\n",
    "    sum_of_f1_score=sum_of_f1_score+f1\n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee599325-5c93-400b-ba24-7d7f4e3cb1bb",
   "metadata": {},
   "source": [
    "First Compare ChatGPT_Tag and GroundTruth_Tag(manual tags of Q1)\n",
    "I have taken List of List of BIO tagging for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "29065306-a605-41c3-a133-c4df23c7a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT_tag=[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O','O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG'],\n",
    " ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O','O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "]\n",
    " \n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "89e90727-bac9-46af-a199-95e146acd420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(ChatGPT_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "66c194c2-0426-4dc9-bb7e-f95e5925279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ground_truth=[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-MISC', 'B-MISC', 'I-MISC', 'O', 'B-PER', 'I-PER', 'I-PER', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-ORG', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG'],\n",
    " ['B-ORG', 'I-ORG', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O','O' ,'B-MISC', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-MISC', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O','O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-ORG', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a49d8a05-e030-479b-9a7c-9d41a249281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(Ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e973c18-30d9-4c25-8121-64b3bba43ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to see there will be no mismatch I print the count of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc6ee291-9ea5-40fd-b29d-c47c373e3596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :: 48 48\n",
      "2 :: 26 26\n",
      "3 :: 41 41\n",
      "4 :: 21 21\n",
      "5 :: 44 44\n",
      "6 :: 21 21\n",
      "7 :: 14 14\n",
      "8 :: 43 43\n",
      "9 :: 12 12\n",
      "10 :: 21 21\n",
      "11 :: 29 29\n",
      "12 :: 17 17\n",
      "13 :: 22 22\n",
      "14 :: 14 14\n",
      "15 :: 24 24\n",
      "16 :: 12 12\n",
      "17 :: 58 58\n",
      "18 :: 14 14\n",
      "19 :: 22 22\n",
      "20 :: 25 25\n",
      "21 :: 23 23\n",
      "22 :: 21 21\n",
      "23 :: 32 32\n",
      "24 :: 51 51\n",
      "25 :: 30 30\n"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "for true_sent, pred_sent in zip(Ground_truth, ChatGPT_tag):\n",
    "    print(count,'::',len(true_sent),len(pred_sent))\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9622b9-5c49-4fab-8b23-1c16af4161c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each class I have calculate precision ,recall and f1 score and at last print the macro f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bc9862e4-ebb3-4b64-8232-4117ae165a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for class:: B-PER\n",
      "False Positive:: 2\n",
      "True Positive:: 15\n",
      "False Negative:: 5\n",
      "Precision:- 0.8823529411764706\n",
      "Recall:- 0.75\n",
      "f1:- 0.8108108108108107\n",
      "\n",
      "for class:: I-PER\n",
      "False Positive:: 1\n",
      "True Positive:: 9\n",
      "False Negative:: 2\n",
      "Precision:- 0.9\n",
      "Recall:- 0.8181818181818182\n",
      "f1:- 0.8571428571428572\n",
      "\n",
      "for class:: B-LOC\n",
      "False Positive:: 2\n",
      "True Positive:: 5\n",
      "False Negative:: 3\n",
      "Precision:- 0.7142857142857143\n",
      "Recall:- 0.625\n",
      "f1:- 0.6666666666666666\n",
      "\n",
      "for class:: I-LOC\n",
      "False Positive:: 3\n",
      "True Positive:: 1\n",
      "False Negative:: 2\n",
      "Precision:- 0.25\n",
      "Recall:- 0.3333333333333333\n",
      "f1:- 0.28571428571428575\n",
      "\n",
      "for class:: B-ORG\n",
      "False Positive:: 1\n",
      "True Positive:: 3\n",
      "False Negative:: 2\n",
      "Precision:- 0.75\n",
      "Recall:- 0.6\n",
      "f1:- 0.6666666666666665\n",
      "\n",
      "for class:: I-ORG\n",
      "False Positive:: 0\n",
      "True Positive:: 3\n",
      "False Negative:: 0\n",
      "Precision:- 1.0\n",
      "Recall:- 1.0\n",
      "f1:- 1.0\n",
      "\n",
      "for class:: B-MISC\n",
      "False Positive:: 1\n",
      "True Positive:: 0\n",
      "False Negative:: 28\n",
      "Precision:- 0.0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: I-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 5\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: O\n",
      "False Positive:: 41\n",
      "True Positive:: 598\n",
      "False Negative:: 4\n",
      "Precision:- 0.9358372456964006\n",
      "Recall:- 0.9933554817275747\n",
      "f1:- 0.9637389202256245\n",
      "\n",
      "macrof1:: 0.583415578580768\n"
     ]
    }
   ],
   "source": [
    "sum_of_f1_score=0\n",
    "calculate(Ground_truth, ChatGPT_tag,'B-PER')\n",
    "calculate(Ground_truth, ChatGPT_tag,'I-PER')\n",
    "calculate(Ground_truth, ChatGPT_tag,'B-LOC')\n",
    "calculate(Ground_truth, ChatGPT_tag,'I-LOC')\n",
    "calculate(Ground_truth, ChatGPT_tag,'B-ORG')\n",
    "calculate(Ground_truth, ChatGPT_tag,'I-ORG')\n",
    "calculate(Ground_truth, ChatGPT_tag,'B-MISC')\n",
    "calculate(Ground_truth, ChatGPT_tag,'I-MISC')\n",
    "calculate(Ground_truth, ChatGPT_tag,'O')\n",
    "macro_f1=sum_of_f1_score/9\n",
    "print('macrof1::',macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ad213-3c2e-406f-bc8f-49e6492032d4",
   "metadata": {},
   "source": [
    "IndicBERT(with 20000 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9ba0b-a589-4504-8e64-82bf56c01caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I load the finetuned IndicBERT model and Tokenizer that I have finetuned in Q2\n",
    "#Please specify the correct path while loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e00f0126-4150-400a-885c-f90e321d89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "model = AutoModelForTokenClassification.from_pretrained('Best/IndicBERTTuned_BatchSize8_weight_decay/kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('Best/IndicBERT_tokenizer_BatchSize8_weight_decay/kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88692e85-7555-4c6b-b88d-90a47683c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function which take a sentence and give ner tags by model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d01ce0b-ec8b-488f-b171-d91ee3f1f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        for index in range(len(sentence.split(' '))):\n",
    "            if(index<len(predicted_labels)):\n",
    "                ner_output.append((sentence.split(' ')[index], predicted_labels[index]))\n",
    "            else:\n",
    "                ner_output.append((sentence.split(' ')[index], 'O'))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd3cd8-540e-439f-a95d-6d0ecaeeff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here while getting tag with the model just to overcome the mismatch of count of tokens I have done padding on correct places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30cd5d85-6431-40f4-a8a0-00ce37d6462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]\n"
     ]
    }
   ],
   "source": [
    "All_sentences=['नारायण साईं पर जेल में रहते हुए पुलिस कर्मचारी को 13 करोड़ रुपए की रिश्वत देने का भी आरोप लगा था, लेकिन इस मामले में नारायण साईं को जमानत तो मिल चुकी है लेकिन रेप के मामले में अभी भी कोर्ट में सुनवाई चल रही है।',\n",
    "           'इसके बाद वह अपनी मां से तब तक विडियो कॉल पर बात करने से बचती रहीं तब तक उन्होंने अपने वेट कम नहीं कर लिया।',\n",
    "           'इससे पहले प्रिंस नरुला ने इस बात की पुष्टि की है कि वह शो की सहभागी एवं मोरक्को की सुंदरी नोरा फातेही के के साथ समय. . . दीप्ति अपहरण मामले पर बोले शाहरुख, लोग फिल्मों से गलत सीख लेते हैं',\n",
    "           'अखिलेश और राहुल पर हमला करते हुए योगी ने कहा कि शहजादे और युवराज का यूपी पर ध्यान नहीं जाता.',\n",
    "           'आषाढ़ माह में बारिश होने से तालाबों में मेढकाें की टर्र-टर्र सुनाई पड़ने लगती थी लेकिन इस बार बेल्हा से बादल इस कदर रूठे रहे कि मई और जून माह में सिर्फ एक मिलीमीटर बारिश हो सकी। बरसाती मेढक दिखे ही नहीं।',\n",
    "           'जानकारी है कि प्रशांत किशोर ने इस काम के लिए राहुल गांधी से कोई भी वेतन नहीं ले रहे हैं.',\n",
    "           'देवासुर संग्राम में शक्ति (नारी) ही चंडी-दुर्गा के रूप में प्रकट होती है।',\n",
    "           'इसका दुष्प्रभाव यह है कि जनप्रतिनिधियों से महत्वपूर्ण पार्टियां हो जाती हैं. फिर पार्टी कमान कंपनी का सीइओ हो जाता है और जनप्रतिनिधि उनके द्वारा नियुक्त होते हैं, केवल औपचारिक तौर पर उनका चुनाव जनता के द्वारा होना जरूरी है.',\n",
    "           'मुंबई: महाराष्ट्र की राजनीति में उठापटक का दौर जारी है.',\n",
    "           '20/08/2014 मुख्य अभियंता, धसान केन कछार सागर के अन्तर्गत गुण नियंत्रण के कार्यों को गति देने हेतु मुख्यालय परिवर्तन।',\n",
    "           'हालांकि, पिछले साल दिसंबर से सभी टेलिकॉम कंपनियों ने अपने प्रीपेड प्लान्स में बदलाव किया था, जिसके बाद ये प्रीपेड प्लान डिसकन्टिन्यू कर दिया गया है.',\n",
    "           'पैनासोनिक ने पेश किए दो स्‍मार्टफोन, कीमत है इनकी 27000 रुपए तक - India TV Paisa',\n",
    "           'एयर इंडिया को सरकार 2100 करोड़ रु की मदद देगी, 6 साल में 26000 करोड़ मिले फिर भी नहीं सुधरी हालत',\n",
    "           'पिछले मैच में हमारे साथ जो हुआ उससे टीम ने काफी कुछ सीखा.',\n",
    "           'सरकारें राजनीतिक दलों की होती हैं और वे जनता के हित में कोई योजना चलाते हैं, जिनमें वायदे ही तो होते हैं।',\n",
    "           'शपथ ग्रहण से पहले बीजेपी में बड़े बदलाव हो सकते हैं।',\n",
    "           'युधिष्ठिर की उदारता भी अलौकिक थी । जब कौरवो ने किसी प्रकार भी इनका राज्य लौटाना मंजूर नहीं किया तो इन्होंने केवल पांच गांव लेकर संतोष करना स्वीकार कर लिया और भगवान् श्रीकृष्णके द्वारा दुर्योधन को यह कहला भेजा कि यदि वह हमें हमारे इच्छानुसार केवल पांच गांव देना मंजूर कर ले तो हम युद्ध न करे ।',\n",
    "           'महंत ने कहा कि अब इंतजार के अलावा कोई विकल्प भी नहीं है।',\n",
    "           'गौरतलब है कि इस मंदिर के सामने की तरफ कुछ मीटर की दूरी पर ही पुलिस का नाका लगा रहता है।',\n",
    "           'इस शपथ ग्रहण समारोह में इस बार एक बात यह खास है कि पाकिस्‍तान के पीएम इमरान खान को न्‍योता नहीं दिया गया है।',\n",
    "           'इसी वजह से मिठाई की जगह पर लोगों ने उपहार देने के लिए ड्राई फ्रूट्स और चौकलेट का प्रयोग करना शुरू किया.',\n",
    "           'उनका कहना है कि प्रदर्शन के विश्लेषण के लिहाज से कम से कम 3-5 साल का नजरिया रखा जाना चाहिए।',\n",
    "           'रेंजर्स ने मशहूर पर्यटक स्थल टाफ्ट प्वाइंट से नीचे गुरुवार को दुर्गम इलाके से उनके शव बरामद किये। टाफ्ट प्वाइंट से योसेमिटी घाटी का मनोरम दृश्य देखने को मिलता है।',\n",
    "           'इसके पहले अपने बयान पर सफाई देते हुए प्रज्ञा सिंह ठाकुर ने ट्वीट किया, कभी-2 झूठ का बबण्डर इतना गहरा होता है कि दिन मे भी रात लगने लगती है किन्तु सूर्य अपना प्रकाश नहीं खोता पलभर के बबण्डर मे लोग भ्रमित न हों सूर्य का प्रकाश स्थाई है।',\n",
    "           'शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है। खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे।'\n",
    "          ]\n",
    "\n",
    "\n",
    "IndicBERT_tag=[]\n",
    "for each_line in All_sentences:\n",
    "    # print(each_line)\n",
    "    output=get_ner(each_line)\n",
    "    # print(output)\n",
    "    List=[]\n",
    "    for index in range(len(output)):\n",
    "        List.append(output[index][1])  #Now I have done padding of NULL just to overcome the mismatch of count of  the model output and ground truth \n",
    "        if output[index][0].find(\",\") != -1 and len(output[index][0])!=1:        \n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\"।\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\".\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\":\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "    # print(List)\n",
    "    IndicBERT_tag.append(List)\n",
    "print(IndicBERT_tag)\n",
    "\n",
    "# for line in IndicBERT_tag:\n",
    "#     print(len(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dc571e23-5597-45b8-8a92-f85a60f14ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndicBERTtag_with_padding=[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'],\n",
    "                           ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], \n",
    "                           ['O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    "                           ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b54a67fa-3e4f-45a7-b78e-2797348d087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :: 48 48\n",
      "2 :: 26 26\n",
      "3 :: 41 41\n",
      "4 :: 21 21\n",
      "5 :: 44 44\n",
      "6 :: 21 21\n",
      "7 :: 14 14\n",
      "8 :: 43 43\n",
      "9 :: 12 12\n",
      "10 :: 21 21\n",
      "11 :: 29 29\n",
      "12 :: 17 17\n",
      "13 :: 22 22\n",
      "14 :: 14 14\n",
      "15 :: 24 24\n",
      "16 :: 12 12\n",
      "17 :: 58 58\n",
      "18 :: 14 14\n",
      "19 :: 22 22\n",
      "20 :: 25 25\n",
      "21 :: 23 23\n",
      "22 :: 21 21\n",
      "23 :: 32 32\n",
      "24 :: 51 51\n",
      "25 :: 30 30\n"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "for true_sent, pred_sent in zip(Ground_truth, IndicBERTtag_with_padding):\n",
    "    print(count,'::',len(true_sent),len(pred_sent))\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "349f8ef4-5d95-4ee0-bdbd-bec5212efc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for class:: B-PER\n",
      "False Positive:: 6\n",
      "True Positive:: 13\n",
      "False Negative:: 7\n",
      "Precision:- 0.6842105263157895\n",
      "Recall:- 0.65\n",
      "f1:- 0.6666666666666667\n",
      "\n",
      "for class:: I-PER\n",
      "False Positive:: 1\n",
      "True Positive:: 6\n",
      "False Negative:: 5\n",
      "Precision:- 0.8571428571428571\n",
      "Recall:- 0.5454545454545454\n",
      "f1:- 0.6666666666666665\n",
      "\n",
      "for class:: B-LOC\n",
      "False Positive:: 5\n",
      "True Positive:: 5\n",
      "False Negative:: 3\n",
      "Precision:- 0.5\n",
      "Recall:- 0.625\n",
      "f1:- 0.5555555555555556\n",
      "\n",
      "for class:: I-LOC\n",
      "False Positive:: 1\n",
      "True Positive:: 2\n",
      "False Negative:: 1\n",
      "Precision:- 0.6666666666666666\n",
      "Recall:- 0.6666666666666666\n",
      "f1:- 0.6666666666666666\n",
      "\n",
      "for class:: B-ORG\n",
      "False Positive:: 3\n",
      "True Positive:: 2\n",
      "False Negative:: 3\n",
      "Precision:- 0.4\n",
      "Recall:- 0.4\n",
      "f1:- 0.4000000000000001\n",
      "\n",
      "for class:: I-ORG\n",
      "False Positive:: 1\n",
      "True Positive:: 2\n",
      "False Negative:: 1\n",
      "Precision:- 0.6666666666666666\n",
      "Recall:- 0.6666666666666666\n",
      "f1:- 0.6666666666666666\n",
      "\n",
      "for class:: B-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 28\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: I-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 5\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: O\n",
      "False Positive:: 44\n",
      "True Positive:: 557\n",
      "False Negative:: 45\n",
      "Precision:- 0.9267886855241264\n",
      "Recall:- 0.925249169435216\n",
      "f1:- 0.9260182876142975\n",
      "\n",
      "macrof1:: 0.5053600566485021\n"
     ]
    }
   ],
   "source": [
    "sum_of_f1_score=0\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-PER')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-PER')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-LOC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-LOC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-ORG')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-ORG')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-MISC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-MISC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'O')\n",
    "macro_f1=sum_of_f1_score/9\n",
    "print('macrof1::',macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d5181c-587a-40d0-960a-87b92f5743c2",
   "metadata": {},
   "source": [
    "IndicNER(with 20000 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbf491-0e09-42f0-a349-dae3d9dcd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I load the finetuned IndicBERT model and Tokenizer that I have finetuned in Q2\n",
    "#Please specify the correct path while loading the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "24a9d32f-4b62-4d95-8d6a-ef4313f7fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "model = AutoModelForTokenClassification.from_pretrained('Best/IndicNERTuned_20000_BatchSize8weightdecay_best/kaggle/working/Finetuned_indicNER_with_20000_sentences_BatchSize=8_weight_1/')\n",
    "tokenizer = AutoTokenizer.from_pretrained('Best/IndicNER_tokenizer_20000_BatchSize8_best/kaggle/working/tokenizer_indicNER_BatchSize=8_weight_1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8df5c320-3cb3-4cc6-82a7-50342ce02549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'NULL', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]\n"
     ]
    }
   ],
   "source": [
    "All_sentences=['नारायण साईं पर जेल में रहते हुए पुलिस कर्मचारी को 13 करोड़ रुपए की रिश्वत देने का भी आरोप लगा था, लेकिन इस मामले में नारायण साईं को जमानत तो मिल चुकी है लेकिन रेप के मामले में अभी भी कोर्ट में सुनवाई चल रही है।',\n",
    "           'इसके बाद वह अपनी मां से तब तक विडियो कॉल पर बात करने से बचती रहीं तब तक उन्होंने अपने वेट कम नहीं कर लिया।',\n",
    "           'इससे पहले प्रिंस नरुला ने इस बात की पुष्टि की है कि वह शो की सहभागी एवं मोरक्को की सुंदरी नोरा फातेही के के साथ समय. . . दीप्ति अपहरण मामले पर बोले शाहरुख, लोग फिल्मों से गलत सीख लेते हैं',\n",
    "           'अखिलेश और राहुल पर हमला करते हुए योगी ने कहा कि शहजादे और युवराज का यूपी पर ध्यान नहीं जाता.',\n",
    "           'आषाढ़ माह में बारिश होने से तालाबों में मेढकाें की टर्र-टर्र सुनाई पड़ने लगती थी लेकिन इस बार बेल्हा से बादल इस कदर रूठे रहे कि मई और जून माह में सिर्फ एक मिलीमीटर बारिश हो सकी। बरसाती मेढक दिखे ही नहीं।',\n",
    "           'जानकारी है कि प्रशांत किशोर ने इस काम के लिए राहुल गांधी से कोई भी वेतन नहीं ले रहे हैं.',\n",
    "           'देवासुर संग्राम में शक्ति (नारी) ही चंडी-दुर्गा के रूप में प्रकट होती है।',\n",
    "           'इसका दुष्प्रभाव यह है कि जनप्रतिनिधियों से महत्वपूर्ण पार्टियां हो जाती हैं. फिर पार्टी कमान कंपनी का सीइओ हो जाता है और जनप्रतिनिधि उनके द्वारा नियुक्त होते हैं, केवल औपचारिक तौर पर उनका चुनाव जनता के द्वारा होना जरूरी है.',\n",
    "           'मुंबई: महाराष्ट्र की राजनीति में उठापटक का दौर जारी है.',\n",
    "           '20/08/2014 मुख्य अभियंता, धसान केन कछार सागर के अन्तर्गत गुण नियंत्रण के कार्यों को गति देने हेतु मुख्यालय परिवर्तन।',\n",
    "           'हालांकि, पिछले साल दिसंबर से सभी टेलिकॉम कंपनियों ने अपने प्रीपेड प्लान्स में बदलाव किया था, जिसके बाद ये प्रीपेड प्लान डिसकन्टिन्यू कर दिया गया है.',\n",
    "           'पैनासोनिक ने पेश किए दो स्‍मार्टफोन, कीमत है इनकी 27000 रुपए तक - India TV Paisa',\n",
    "           'एयर इंडिया को सरकार 2100 करोड़ रु की मदद देगी, 6 साल में 26000 करोड़ मिले फिर भी नहीं सुधरी हालत',\n",
    "           'पिछले मैच में हमारे साथ जो हुआ उससे टीम ने काफी कुछ सीखा.',\n",
    "           'सरकारें राजनीतिक दलों की होती हैं और वे जनता के हित में कोई योजना चलाते हैं, जिनमें वायदे ही तो होते हैं।',\n",
    "           'शपथ ग्रहण से पहले बीजेपी में बड़े बदलाव हो सकते हैं।',\n",
    "           'युधिष्ठिर की उदारता भी अलौकिक थी । जब कौरवो ने किसी प्रकार भी इनका राज्य लौटाना मंजूर नहीं किया तो इन्होंने केवल पांच गांव लेकर संतोष करना स्वीकार कर लिया और भगवान् श्रीकृष्णके द्वारा दुर्योधन को यह कहला भेजा कि यदि वह हमें हमारे इच्छानुसार केवल पांच गांव देना मंजूर कर ले तो हम युद्ध न करे ।',\n",
    "           'महंत ने कहा कि अब इंतजार के अलावा कोई विकल्प भी नहीं है।',\n",
    "           'गौरतलब है कि इस मंदिर के सामने की तरफ कुछ मीटर की दूरी पर ही पुलिस का नाका लगा रहता है।',\n",
    "           'इस शपथ ग्रहण समारोह में इस बार एक बात यह खास है कि पाकिस्‍तान के पीएम इमरान खान को न्‍योता नहीं दिया गया है।',\n",
    "           'इसी वजह से मिठाई की जगह पर लोगों ने उपहार देने के लिए ड्राई फ्रूट्स और चौकलेट का प्रयोग करना शुरू किया.',\n",
    "           'उनका कहना है कि प्रदर्शन के विश्लेषण के लिहाज से कम से कम 3-5 साल का नजरिया रखा जाना चाहिए।',\n",
    "           'रेंजर्स ने मशहूर पर्यटक स्थल टाफ्ट प्वाइंट से नीचे गुरुवार को दुर्गम इलाके से उनके शव बरामद किये। टाफ्ट प्वाइंट से योसेमिटी घाटी का मनोरम दृश्य देखने को मिलता है।',\n",
    "           'इसके पहले अपने बयान पर सफाई देते हुए प्रज्ञा सिंह ठाकुर ने ट्वीट किया, कभी-2 झूठ का बबण्डर इतना गहरा होता है कि दिन मे भी रात लगने लगती है किन्तु सूर्य अपना प्रकाश नहीं खोता पलभर के बबण्डर मे लोग भ्रमित न हों सूर्य का प्रकाश स्थाई है।',\n",
    "           'शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है। खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे।'\n",
    "          ]\n",
    "IndicNER_tag=[]\n",
    "for each_line in All_sentences:\n",
    "    # print(each_line)\n",
    "    output=get_ner(each_line)\n",
    "    # print(output)\n",
    "    List=[]\n",
    "    for index in range(len(output)):\n",
    "        List.append(output[index][1])    #Now I have done padding of NULL just to overcome the mismatch of count of  the model output and ground truth\n",
    "        if output[index][0].find(\",\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\"।\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\".\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\":\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        \n",
    "    # print(List)\n",
    "    IndicNER_tag.append(List)\n",
    "print(IndicNER_tag)\n",
    "\n",
    "\n",
    "# count=1\n",
    "# for line in IndicBERT_tag:\n",
    "#     print(count,'::',len(line))\n",
    "#     count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5fd25329-aaa4-48ef-9b9b-423f8575eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndicNERtagging_withpadding=[['B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], \n",
    "                             ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], \n",
    "                             ['O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    "                             ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40a8ede5-ce8a-46cf-91a2-8284da536aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :: 48 48\n",
      "2 :: 26 26\n",
      "3 :: 41 41\n",
      "4 :: 21 21\n",
      "5 :: 44 44\n",
      "6 :: 21 21\n",
      "7 :: 14 14\n",
      "8 :: 43 43\n",
      "9 :: 12 12\n",
      "10 :: 21 21\n",
      "11 :: 29 29\n",
      "12 :: 17 17\n",
      "13 :: 22 22\n",
      "14 :: 14 14\n",
      "15 :: 24 24\n",
      "16 :: 12 12\n",
      "17 :: 58 58\n",
      "18 :: 14 14\n",
      "19 :: 22 22\n",
      "20 :: 25 25\n",
      "21 :: 23 23\n",
      "22 :: 21 21\n",
      "23 :: 32 32\n",
      "24 :: 51 51\n",
      "25 :: 30 30\n"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "for true_sent, pred_sent in zip(Ground_truth, IndicNERtagging_withpadding):\n",
    "    print(count,'::',len(true_sent),len(pred_sent))\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "96eee395-aa03-42bf-b9c1-f92bc3df9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for class:: B-PER\n",
      "False Positive:: 10\n",
      "True Positive:: 13\n",
      "False Negative:: 7\n",
      "Precision:- 0.5652173913043478\n",
      "Recall:- 0.65\n",
      "f1:- 0.6046511627906976\n",
      "\n",
      "for class:: I-PER\n",
      "False Positive:: 0\n",
      "True Positive:: 5\n",
      "False Negative:: 6\n",
      "Precision:- 1.0\n",
      "Recall:- 0.45454545454545453\n",
      "f1:- 0.625\n",
      "\n",
      "for class:: B-LOC\n",
      "False Positive:: 4\n",
      "True Positive:: 4\n",
      "False Negative:: 4\n",
      "Precision:- 0.5\n",
      "Recall:- 0.5\n",
      "f1:- 0.5\n",
      "\n",
      "for class:: I-LOC\n",
      "False Positive:: 5\n",
      "True Positive:: 1\n",
      "False Negative:: 2\n",
      "Precision:- 0.16666666666666666\n",
      "Recall:- 0.3333333333333333\n",
      "f1:- 0.2222222222222222\n",
      "\n",
      "for class:: B-ORG\n",
      "False Positive:: 2\n",
      "True Positive:: 3\n",
      "False Negative:: 2\n",
      "Precision:- 0.6\n",
      "Recall:- 0.6\n",
      "f1:- 0.6\n",
      "\n",
      "for class:: I-ORG\n",
      "False Positive:: 0\n",
      "True Positive:: 2\n",
      "False Negative:: 1\n",
      "Precision:- 1.0\n",
      "Recall:- 0.6666666666666666\n",
      "f1:- 0.8\n",
      "\n",
      "for class:: B-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 28\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: I-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 5\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: O\n",
      "False Positive:: 50\n",
      "True Positive:: 549\n",
      "False Negative:: 53\n",
      "Precision:- 0.9165275459098498\n",
      "Recall:- 0.9119601328903655\n",
      "f1:- 0.9142381348875938\n",
      "\n",
      "macrof1:: 0.47401239110005705\n"
     ]
    }
   ],
   "source": [
    "sum_of_f1_score=0\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'B-PER')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'I-PER')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'B-LOC')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'I-LOC')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'B-ORG')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'I-ORG')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'B-MISC')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'I-MISC')\n",
    "calculate(Ground_truth, IndicNERtagging_withpadding,'O')\n",
    "macro_f1=sum_of_f1_score/9\n",
    "print('macrof1::',macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed048d9-6cfd-471e-a0a3-9cfb5f7343c7",
   "metadata": {},
   "source": [
    "Extra::IndicBERT(with 20% of training Data with 2 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e2f5975-32cd-4a70-a6fe-e200a308c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "model = AutoModelForTokenClassification.from_pretrained('BertTuned/kaggle/working/my_indicBERT')\n",
    "tokenizer = AutoTokenizer.from_pretrained('BertTuned_tokenizer/kaggle/working/tokenizer_indicBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4c72e10a-6f34-4bcc-ace2-fb3f345c897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]\n"
     ]
    }
   ],
   "source": [
    "All_sentences=['नारायण साईं पर जेल में रहते हुए पुलिस कर्मचारी को 13 करोड़ रुपए की रिश्वत देने का भी आरोप लगा था, लेकिन इस मामले में नारायण साईं को जमानत तो मिल चुकी है लेकिन रेप के मामले में अभी भी कोर्ट में सुनवाई चल रही है।',\n",
    "           'इसके बाद वह अपनी मां से तब तक विडियो कॉल पर बात करने से बचती रहीं तब तक उन्होंने अपने वेट कम नहीं कर लिया।',\n",
    "           'इससे पहले प्रिंस नरुला ने इस बात की पुष्टि की है कि वह शो की सहभागी एवं मोरक्को की सुंदरी नोरा फातेही के के साथ समय. . . दीप्ति अपहरण मामले पर बोले शाहरुख, लोग फिल्मों से गलत सीख लेते हैं',\n",
    "           'अखिलेश और राहुल पर हमला करते हुए योगी ने कहा कि शहजादे और युवराज का यूपी पर ध्यान नहीं जाता.',\n",
    "           'आषाढ़ माह में बारिश होने से तालाबों में मेढकाें की टर्र-टर्र सुनाई पड़ने लगती थी लेकिन इस बार बेल्हा से बादल इस कदर रूठे रहे कि मई और जून माह में सिर्फ एक मिलीमीटर बारिश हो सकी। बरसाती मेढक दिखे ही नहीं।',\n",
    "           'जानकारी है कि प्रशांत किशोर ने इस काम के लिए राहुल गांधी से कोई भी वेतन नहीं ले रहे हैं.',\n",
    "           'देवासुर संग्राम में शक्ति (नारी) ही चंडी-दुर्गा के रूप में प्रकट होती है।',\n",
    "           'इसका दुष्प्रभाव यह है कि जनप्रतिनिधियों से महत्वपूर्ण पार्टियां हो जाती हैं. फिर पार्टी कमान कंपनी का सीइओ हो जाता है और जनप्रतिनिधि उनके द्वारा नियुक्त होते हैं, केवल औपचारिक तौर पर उनका चुनाव जनता के द्वारा होना जरूरी है.',\n",
    "           'मुंबई: महाराष्ट्र की राजनीति में उठापटक का दौर जारी है.',\n",
    "           '20/08/2014 मुख्य अभियंता, धसान केन कछार सागर के अन्तर्गत गुण नियंत्रण के कार्यों को गति देने हेतु मुख्यालय परिवर्तन।',\n",
    "           'हालांकि, पिछले साल दिसंबर से सभी टेलिकॉम कंपनियों ने अपने प्रीपेड प्लान्स में बदलाव किया था, जिसके बाद ये प्रीपेड प्लान डिसकन्टिन्यू कर दिया गया है.',\n",
    "           'पैनासोनिक ने पेश किए दो स्‍मार्टफोन, कीमत है इनकी 27000 रुपए तक - India TV Paisa',\n",
    "           'एयर इंडिया को सरकार 2100 करोड़ रु की मदद देगी, 6 साल में 26000 करोड़ मिले फिर भी नहीं सुधरी हालत',\n",
    "           'पिछले मैच में हमारे साथ जो हुआ उससे टीम ने काफी कुछ सीखा.',\n",
    "           'सरकारें राजनीतिक दलों की होती हैं और वे जनता के हित में कोई योजना चलाते हैं, जिनमें वायदे ही तो होते हैं।',\n",
    "           'शपथ ग्रहण से पहले बीजेपी में बड़े बदलाव हो सकते हैं।',\n",
    "           'युधिष्ठिर की उदारता भी अलौकिक थी । जब कौरवो ने किसी प्रकार भी इनका राज्य लौटाना मंजूर नहीं किया तो इन्होंने केवल पांच गांव लेकर संतोष करना स्वीकार कर लिया और भगवान् श्रीकृष्णके द्वारा दुर्योधन को यह कहला भेजा कि यदि वह हमें हमारे इच्छानुसार केवल पांच गांव देना मंजूर कर ले तो हम युद्ध न करे ।',\n",
    "           'महंत ने कहा कि अब इंतजार के अलावा कोई विकल्प भी नहीं है।',\n",
    "           'गौरतलब है कि इस मंदिर के सामने की तरफ कुछ मीटर की दूरी पर ही पुलिस का नाका लगा रहता है।',\n",
    "           'इस शपथ ग्रहण समारोह में इस बार एक बात यह खास है कि पाकिस्‍तान के पीएम इमरान खान को न्‍योता नहीं दिया गया है।',\n",
    "           'इसी वजह से मिठाई की जगह पर लोगों ने उपहार देने के लिए ड्राई फ्रूट्स और चौकलेट का प्रयोग करना शुरू किया.',\n",
    "           'उनका कहना है कि प्रदर्शन के विश्लेषण के लिहाज से कम से कम 3-5 साल का नजरिया रखा जाना चाहिए।',\n",
    "           'रेंजर्स ने मशहूर पर्यटक स्थल टाफ्ट प्वाइंट से नीचे गुरुवार को दुर्गम इलाके से उनके शव बरामद किये। टाफ्ट प्वाइंट से योसेमिटी घाटी का मनोरम दृश्य देखने को मिलता है।',\n",
    "           'इसके पहले अपने बयान पर सफाई देते हुए प्रज्ञा सिंह ठाकुर ने ट्वीट किया, कभी-2 झूठ का बबण्डर इतना गहरा होता है कि दिन मे भी रात लगने लगती है किन्तु सूर्य अपना प्रकाश नहीं खोता पलभर के बबण्डर मे लोग भ्रमित न हों सूर्य का प्रकाश स्थाई है।',\n",
    "           'शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है। खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे।'\n",
    "          ]\n",
    "IndicBERT_tag=[]\n",
    "for each_line in All_sentences:\n",
    "    # print(each_line)\n",
    "    output=get_ner(each_line)\n",
    "    # print(output)\n",
    "    List=[]\n",
    "    for index in range(len(output)):\n",
    "        List.append(output[index][1])\n",
    "        if output[index][0].find(\",\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\"।\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\".\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\":\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "    # print(List)\n",
    "    IndicBERT_tag.append(List)\n",
    "print(IndicBERT_tag)\n",
    "\n",
    "# for line in IndicBERT_tag:\n",
    "#     print(len(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7c89eb5d-b414-4c89-9cca-97b60f9c0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndicBERTtag_with_padding=[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'],\n",
    " ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], \n",
    " ['O', 'O', 'B-PER', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
    " ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81372882-91e9-4cf4-8867-09eb16247751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :: 48 48\n",
      "2 :: 26 26\n",
      "3 :: 41 41\n",
      "4 :: 21 21\n",
      "5 :: 44 44\n",
      "6 :: 21 21\n",
      "7 :: 14 14\n",
      "8 :: 43 43\n",
      "9 :: 12 12\n",
      "10 :: 21 21\n",
      "11 :: 29 29\n",
      "12 :: 17 17\n",
      "13 :: 22 22\n",
      "14 :: 14 14\n",
      "15 :: 24 24\n",
      "16 :: 12 12\n",
      "17 :: 58 58\n",
      "18 :: 14 14\n",
      "19 :: 22 22\n",
      "20 :: 25 25\n",
      "21 :: 23 23\n",
      "22 :: 21 21\n",
      "23 :: 32 32\n",
      "24 :: 51 51\n",
      "25 :: 30 30\n"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "for true_sent, pred_sent in zip(Ground_truth, IndicBERTtag_with_padding):\n",
    "    print(count,'::',len(true_sent),len(pred_sent))\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d4bcc3c3-7985-4072-9196-bf94b95b2ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for class:: B-PER\n",
      "False Positive:: 7\n",
      "True Positive:: 13\n",
      "False Negative:: 7\n",
      "Precision:- 0.65\n",
      "Recall:- 0.65\n",
      "f1:- 0.65\n",
      "\n",
      "for class:: I-PER\n",
      "False Positive:: 2\n",
      "True Positive:: 7\n",
      "False Negative:: 4\n",
      "Precision:- 0.7777777777777778\n",
      "Recall:- 0.6363636363636364\n",
      "f1:- 0.7000000000000001\n",
      "\n",
      "for class:: B-LOC\n",
      "False Positive:: 1\n",
      "True Positive:: 6\n",
      "False Negative:: 2\n",
      "Precision:- 0.8571428571428571\n",
      "Recall:- 0.75\n",
      "f1:- 0.7999999999999999\n",
      "\n",
      "for class:: I-LOC\n",
      "False Positive:: 0\n",
      "True Positive:: 3\n",
      "False Negative:: 0\n",
      "Precision:- 1.0\n",
      "Recall:- 1.0\n",
      "f1:- 1.0\n",
      "\n",
      "for class:: B-ORG\n",
      "False Positive:: 1\n",
      "True Positive:: 2\n",
      "False Negative:: 3\n",
      "Precision:- 0.6666666666666666\n",
      "Recall:- 0.4\n",
      "f1:- 0.5\n",
      "\n",
      "for class:: I-ORG\n",
      "False Positive:: 1\n",
      "True Positive:: 2\n",
      "False Negative:: 1\n",
      "Precision:- 0.6666666666666666\n",
      "Recall:- 0.6666666666666666\n",
      "f1:- 0.6666666666666666\n",
      "\n",
      "for class:: B-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 28\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: I-MISC\n",
      "False Positive:: 0\n",
      "True Positive:: 0\n",
      "False Negative:: 5\n",
      "Precision:- 0\n",
      "Recall:- 0.0\n",
      "f1:- 0\n",
      "\n",
      "for class:: O\n",
      "False Positive:: 42\n",
      "True Positive:: 561\n",
      "False Negative:: 41\n",
      "Precision:- 0.9303482587064676\n",
      "Recall:- 0.9318936877076412\n",
      "f1:- 0.9311203319502075\n",
      "\n",
      "macrof1:: 0.5830874442907638\n"
     ]
    }
   ],
   "source": [
    "sum_of_f1_score=0\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-PER')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-PER')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-LOC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-LOC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-ORG')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-ORG')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'B-MISC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'I-MISC')\n",
    "calculate(Ground_truth, IndicBERTtag_with_padding,'O')\n",
    "macro_f1=sum_of_f1_score/9\n",
    "print('macrof1::',macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc866f8-b0e8-485d-99d7-57f78fa44faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
