{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:24:07.088773Z",
     "iopub.status.busy": "2024-03-12T16:24:07.088027Z",
     "iopub.status.idle": "2024-03-12T16:25:04.227031Z",
     "shell.execute_reply": "2024-03-12T16:25:04.225959Z",
     "shell.execute_reply.started": "2024-03-12T16:24:07.088743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m634.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c673be8b7d31a9a284977d716d602f1bb2c2d93d01311dbe7e400c0bbf7e5103\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install sentencepiece\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:33:31.578527Z",
     "iopub.status.busy": "2024-03-12T16:33:31.577761Z",
     "iopub.status.idle": "2024-03-12T16:37:03.998327Z",
     "shell.execute_reply": "2024-03-12T16:37:03.997456Z",
     "shell.execute_reply.started": "2024-03-12T16:33:31.578495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ea10c8d0f54c0a96dcac9ec9a8e8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset naamapadam_pr/hi to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739761bec7384dfb915c198a81931ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/82.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset naamapadam_pr downloaded and prepared to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c9bd79d5964e228480490801d12244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's download the Naampadam (Indic NER) dataset\n",
    "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
    "\n",
    "lang='hi'\n",
    "\n",
    "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:37:07.760702Z",
     "iopub.status.busy": "2024-03-12T16:37:07.759661Z",
     "iopub.status.idle": "2024-03-12T16:37:07.766091Z",
     "shell.execute_reply": "2024-03-12T16:37:07.765194Z",
     "shell.execute_reply.started": "2024-03-12T16:37:07.760667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokens', 'ner_tags']\n",
      "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "column_names = raw_datasets[\"train\"].column_names\n",
    "print(column_names)\n",
    "\n",
    "features = raw_datasets[\"train\"].features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:37:10.472325Z",
     "iopub.status.busy": "2024-03-12T16:37:10.471314Z",
     "iopub.status.idle": "2024-03-12T16:37:10.480854Z",
     "shell.execute_reply": "2024-03-12T16:37:10.479953Z",
     "shell.execute_reply.started": "2024-03-12T16:37:10.472281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
     ]
    }
   ],
   "source": [
    "text_column_name = \"tokens\"\n",
    "label_column_name = \"ner_tags\"\n",
    "label_list = features[label_column_name].feature.names\n",
    "\n",
    "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
    "\n",
    "print(label_to_id)\n",
    "\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:37:13.914230Z",
     "iopub.status.busy": "2024-03-12T16:37:13.912975Z",
     "iopub.status.idle": "2024-03-12T16:37:46.977949Z",
     "shell.execute_reply": "2024-03-12T16:37:46.977126Z",
     "shell.execute_reply.started": "2024-03-12T16:37:13.914186Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 16:37:28.820361: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 16:37:28.820473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 16:37:29.104416: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0110687622594a26abb76707353ba318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccac28be0d664aec85f2ca43332e6cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84c7906d10a4702b51ea81b80d231fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
    "import numpy as np\n",
    "\n",
    "config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:29.759537Z",
     "iopub.status.busy": "2024-03-12T16:39:29.758679Z",
     "iopub.status.idle": "2024-03-12T16:39:30.036801Z",
     "shell.execute_reply": "2024-03-12T16:39:30.035851Z",
     "shell.execute_reply.started": "2024-03-12T16:39:29.759505Z"
    }
   },
   "outputs": [],
   "source": [
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:32.898289Z",
     "iopub.status.busy": "2024-03-12T16:39:32.897831Z",
     "iopub.status.idle": "2024-03-12T16:39:32.906655Z",
     "shell.execute_reply": "2024-03-12T16:39:32.905718Z",
     "shell.execute_reply.started": "2024-03-12T16:39:32.898257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts and align the labels with them.\n",
    "padding = \"max_length\"\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[text_column_name],\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[label_column_name]):\n",
    "        # print('=====')\n",
    "        # print('{} {}'.format(i,label)) #ak\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:39.142055Z",
     "iopub.status.busy": "2024-03-12T16:39:39.141670Z",
     "iopub.status.idle": "2024-03-12T16:39:39.147336Z",
     "shell.execute_reply": "2024-03-12T16:39:39.146449Z",
     "shell.execute_reply.started": "2024-03-12T16:39:39.142025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49289\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the original training set\n",
    "original_train_size = len(raw_datasets[\"train\"])\n",
    "\n",
    "# Calculate the number of samples to keep for 20% of the original training set\n",
    "new_train_size = int(original_train_size * 0.05)\n",
    "print(new_train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:41.428396Z",
     "iopub.status.busy": "2024-03-12T16:39:41.427783Z",
     "iopub.status.idle": "2024-03-12T16:39:48.048701Z",
     "shell.execute_reply": "2024-03-12T16:39:48.047767Z",
     "shell.execute_reply.started": "2024-03-12T16:39:41.428362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed9ab8743274599b4f6aca1c2c7ff3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 20000 sentences of train dataset #0:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e3522f462b483db83a7a3b5a82c77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 20000 sentences of train dataset #1:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2172da3cb52e4d1091e8be06079e6f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 20000 sentences of train dataset #2:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e9f96b42a5445a9c9967ff43868292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on 20000 sentences of train dataset #3:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Get the length of the original training set\n",
    "# original_train_size = len(raw_datasets[\"train\"])\n",
    "\n",
    "# # Calculate the number of samples to keep for 20% of the original training set\n",
    "# new_train_size = int(original_train_size * 0.05)\n",
    "train_dataset = raw_datasets[\"train\"].select(range(20000))\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on 20000 sentences of train dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:48.051098Z",
     "iopub.status.busy": "2024-03-12T16:39:48.050795Z",
     "iopub.status.idle": "2024-03-12T16:39:53.240231Z",
     "shell.execute_reply": "2024-03-12T16:39:53.239217Z",
     "shell.execute_reply.started": "2024-03-12T16:39:48.051073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721d26b9ee3d438ba30fdb4213c4fe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #0:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fde4032ab5d435aac8d3fc22abfe1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #1:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d480fce781844df9aaca5cd347a9695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #3:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd9de4ad7ae4019b08dfeb0530e56c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on Validation dataset #2:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "eval_dataset = eval_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on Validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:39:57.982299Z",
     "iopub.status.busy": "2024-03-12T16:39:57.981583Z",
     "iopub.status.idle": "2024-03-12T16:39:57.986854Z",
     "shell.execute_reply": "2024-03-12T16:39:57.985997Z",
     "shell.execute_reply.started": "2024-03-12T16:39:57.982263Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T16:40:08.023888Z",
     "iopub.status.busy": "2024-03-12T16:40:08.023113Z",
     "iopub.status.idle": "2024-03-12T16:40:08.248686Z",
     "shell.execute_reply": "2024-03-12T16:40:08.247891Z",
     "shell.execute_reply.started": "2024-03-12T16:40:08.023858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    # Unpack nested dictionaries\n",
    "    final_results = {}\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value, dict):\n",
    "            for n, v in value.items():\n",
    "                final_results[f\"{key}_{n}\"] = v\n",
    "        else:\n",
    "            final_results[key] = value\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args=TrainingArguments(\n",
    "#     output_dir='output_dir',\n",
    "#     per_device_train_batch_size=12,\n",
    "#     per_device_eval_batch_size=12,\n",
    "#     num_train_epochs=3,\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     learning_rate=2e-5)\n",
    "\n",
    "# args=TrainingArguments(\n",
    "#     output_dir='output_dir',\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     learning_rate=3e-5)\n",
    "\n",
    "# args=TrainingArguments(\n",
    "#     output_dir='output_dir',\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     learning_rate=4e-5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T18:03:26.626458Z",
     "iopub.status.busy": "2024-03-12T18:03:26.625550Z",
     "iopub.status.idle": "2024-03-12T18:03:26.639040Z",
     "shell.execute_reply": "2024-03-12T18:03:26.638015Z",
     "shell.execute_reply.started": "2024-03-12T18:03:26.626422Z"
    }
   },
   "outputs": [],
   "source": [
    "args=TrainingArguments(\n",
    "    output_dir='output_dir',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=4e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T18:03:29.440378Z",
     "iopub.status.busy": "2024-03-12T18:03:29.439667Z",
     "iopub.status.idle": "2024-03-12T18:03:29.501653Z",
     "shell.execute_reply": "2024-03-12T18:03:29.500526Z",
     "shell.execute_reply.started": "2024-03-12T18:03:29.440343Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[early_stopping_callback],\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T18:03:31.393591Z",
     "iopub.status.busy": "2024-03-12T18:03:31.393219Z",
     "iopub.status.idle": "2024-03-12T18:03:31.404493Z",
     "shell.execute_reply": "2024-03-12T18:03:31.403109Z",
     "shell.execute_reply.started": "2024-03-12T18:03:31.393563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=2,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=4e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=output_dir/runs/Mar12_18-03-26_d57c7d01a179,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=output_dir,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard', 'wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=output_dir,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=steps,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=None,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T18:03:43.504761Z",
     "iopub.status.busy": "2024-03-12T18:03:43.503884Z",
     "iopub.status.idle": "2024-03-12T19:03:26.287346Z",
     "shell.execute_reply": "2024-03-12T19:03:26.286359Z",
     "shell.execute_reply.started": "2024-03-12T18:03:43.504729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 59:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc Precision</th>\n",
       "      <th>Loc Recall</th>\n",
       "      <th>Loc F1</th>\n",
       "      <th>Loc Number</th>\n",
       "      <th>Org Precision</th>\n",
       "      <th>Org Recall</th>\n",
       "      <th>Org F1</th>\n",
       "      <th>Org Number</th>\n",
       "      <th>Per Precision</th>\n",
       "      <th>Per Recall</th>\n",
       "      <th>Per F1</th>\n",
       "      <th>Per Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.274220</td>\n",
       "      <td>0.693958</td>\n",
       "      <td>0.725350</td>\n",
       "      <td>0.709307</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.621670</td>\n",
       "      <td>0.460249</td>\n",
       "      <td>0.528918</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.683310</td>\n",
       "      <td>0.683762</td>\n",
       "      <td>0.683536</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.671627</td>\n",
       "      <td>0.626100</td>\n",
       "      <td>0.648065</td>\n",
       "      <td>0.916689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.261667</td>\n",
       "      <td>0.724060</td>\n",
       "      <td>0.722217</td>\n",
       "      <td>0.723137</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.574646</td>\n",
       "      <td>0.547517</td>\n",
       "      <td>0.560754</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.728711</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.656231</td>\n",
       "      <td>0.667188</td>\n",
       "      <td>0.920915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.272273</td>\n",
       "      <td>0.715746</td>\n",
       "      <td>0.733477</td>\n",
       "      <td>0.724503</td>\n",
       "      <td>10213</td>\n",
       "      <td>0.566542</td>\n",
       "      <td>0.556816</td>\n",
       "      <td>0.561637</td>\n",
       "      <td>9786</td>\n",
       "      <td>0.713807</td>\n",
       "      <td>0.705905</td>\n",
       "      <td>0.709834</td>\n",
       "      <td>10568</td>\n",
       "      <td>0.668086</td>\n",
       "      <td>0.667386</td>\n",
       "      <td>0.667736</td>\n",
       "      <td>0.920288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory output_dir/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-3000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Checkpoint destination directory output_dir/checkpoint-3500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumoff1score=0.837284+0.691080+0.822703\n",
    "macrof1=sumoff1score/3\n",
    "print(macrof1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:04:31.140721Z",
     "iopub.status.busy": "2024-03-12T19:04:31.139760Z",
     "iopub.status.idle": "2024-03-12T19:08:55.646300Z",
     "shell.execute_reply": "2024-03-12T19:08:55.645233Z",
     "shell.execute_reply.started": "2024-03-12T19:04:31.140684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_LOC_f1             =     0.7245\n",
      "  eval_LOC_number         =      10213\n",
      "  eval_LOC_precision      =     0.7157\n",
      "  eval_LOC_recall         =     0.7335\n",
      "  eval_ORG_f1             =     0.5616\n",
      "  eval_ORG_number         =       9786\n",
      "  eval_ORG_precision      =     0.5665\n",
      "  eval_ORG_recall         =     0.5568\n",
      "  eval_PER_f1             =     0.7098\n",
      "  eval_PER_number         =      10568\n",
      "  eval_PER_precision      =     0.7138\n",
      "  eval_PER_recall         =     0.7059\n",
      "  eval_loss               =     0.2723\n",
      "  eval_overall_accuracy   =     0.9203\n",
      "  eval_overall_f1         =     0.6677\n",
      "  eval_overall_precision  =     0.6681\n",
      "  eval_overall_recall     =     0.6674\n",
      "  eval_runtime            = 0:04:24.46\n",
      "  eval_samples_per_second =     50.895\n",
      "  eval_steps_per_second   =      3.184\n"
     ]
    }
   ],
   "source": [
    "Final_metrics = trainer.evaluate()\n",
    "\n",
    "trainer.log_metrics(\"eval\", Final_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:09:54.923801Z",
     "iopub.status.busy": "2024-03-12T19:09:54.922879Z",
     "iopub.status.idle": "2024-03-12T19:09:55.237707Z",
     "shell.execute_reply": "2024-03-12T19:09:55.236400Z",
     "shell.execute_reply.started": "2024-03-12T19:09:54.923769Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('Finetuned_indicBERT_with_20000_sentences_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:14.689838Z",
     "iopub.status.busy": "2024-03-12T19:10:14.689183Z",
     "iopub.status.idle": "2024-03-12T19:10:14.753438Z",
     "shell.execute_reply": "2024-03-12T19:10:14.752416Z",
     "shell.execute_reply.started": "2024-03-12T19:10:14.689805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer_indicBERT_with_20000_sentences_2/tokenizer_config.json',\n",
       " 'tokenizer_indicBERT_with_20000_sentences_2/special_tokens_map.json',\n",
       " 'tokenizer_indicBERT_with_20000_sentences_2/spiece.model',\n",
       " 'tokenizer_indicBERT_with_20000_sentences_2/added_tokens.json',\n",
       " 'tokenizer_indicBERT_with_20000_sentences_2/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"tokenizer_indicBERT_with_20000_sentences_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:40.385474Z",
     "iopub.status.busy": "2024-03-12T19:10:40.385059Z",
     "iopub.status.idle": "2024-03-12T19:10:40.393133Z",
     "shell.execute_reply": "2024-03-12T19:10:40.391410Z",
     "shell.execute_reply.started": "2024-03-12T19:10:40.385445Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    str(i): label for i,label in enumerate(label_list)\n",
    "}\n",
    "label2id = {\n",
    "    label: str(i) for i,label in enumerate(label_list)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:50.328775Z",
     "iopub.status.busy": "2024-03-12T19:10:50.328309Z",
     "iopub.status.idle": "2024-03-12T19:10:50.335877Z",
     "shell.execute_reply": "2024-03-12T19:10:50.334686Z",
     "shell.execute_reply.started": "2024-03-12T19:10:50.328724Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config = json.load(open(\"/kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:10:54.340370Z",
     "iopub.status.busy": "2024-03-12T19:10:54.339996Z",
     "iopub.status.idle": "2024-03-12T19:10:54.346674Z",
     "shell.execute_reply": "2024-03-12T19:10:54.345593Z",
     "shell.execute_reply.started": "2024-03-12T19:10:54.340344Z"
    }
   },
   "outputs": [],
   "source": [
    "config[\"id2label\"] = id2label\n",
    "config[\"label2id\"] = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:01.911762Z",
     "iopub.status.busy": "2024-03-12T19:11:01.910850Z",
     "iopub.status.idle": "2024-03-12T19:11:01.918501Z",
     "shell.execute_reply": "2024-03-12T19:11:01.917417Z",
     "shell.execute_reply.started": "2024-03-12T19:11:01.911727Z"
    }
   },
   "outputs": [],
   "source": [
    "json.dump(config, open(\"/kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/config.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:15.903144Z",
     "iopub.status.busy": "2024-03-12T19:11:15.902735Z",
     "iopub.status.idle": "2024-03-12T19:11:15.974156Z",
     "shell.execute_reply": "2024-03-12T19:11:15.973013Z",
     "shell.execute_reply.started": "2024-03-12T19:11:15.903114Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('/kaggle/working/Finetuned_indicBERT_with_20000_sentences_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:18.694519Z",
     "iopub.status.busy": "2024-03-12T19:11:18.693816Z",
     "iopub.status.idle": "2024-03-12T19:11:18.705357Z",
     "shell.execute_reply": "2024-03-12T19:11:18.702834Z",
     "shell.execute_reply.started": "2024-03-12T19:11:18.694484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForTokenClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:26.734828Z",
     "iopub.status.busy": "2024-03-12T19:11:26.734428Z",
     "iopub.status.idle": "2024-03-12T19:11:26.746493Z",
     "shell.execute_reply": "2024-03-12T19:11:26.744354Z",
     "shell.execute_reply.started": "2024-03-12T19:11:26.734793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertConfig {\n",
       "  \"_name_or_path\": \"/kaggle/working/Finetuned_indicBERT_with_20000_sentences_2\",\n",
       "  \"architectures\": [\n",
       "    \"AlbertForTokenClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"classifier_dropout_prob\": 0.1,\n",
       "  \"down_scale_factor\": 1,\n",
       "  \"embedding_size\": 128,\n",
       "  \"eos_token_id\": 3,\n",
       "  \"gap_size\": 0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-PER\",\n",
       "    \"2\": \"I-PER\",\n",
       "    \"3\": \"B-ORG\",\n",
       "    \"4\": \"I-ORG\",\n",
       "    \"5\": \"B-LOC\",\n",
       "    \"6\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"inner_group_num\": 1,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": \"5\",\n",
       "    \"B-ORG\": \"3\",\n",
       "    \"B-PER\": \"1\",\n",
       "    \"I-LOC\": \"6\",\n",
       "    \"I-ORG\": \"4\",\n",
       "    \"I-PER\": \"2\",\n",
       "    \"O\": \"0\"\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"albert\",\n",
       "  \"net_structure_type\": 0,\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_groups\": 1,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"num_memory_blocks\": 0,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.38.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 200000\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:27:10.468085Z",
     "iopub.status.busy": "2024-03-12T19:27:10.467401Z",
     "iopub.status.idle": "2024-03-12T19:27:19.175327Z",
     "shell.execute_reply": "2024-03-12T19:27:19.173903Z",
     "shell.execute_reply.started": "2024-03-12T19:27:10.468033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/ (stored 0%)\n",
      "  adding: kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/config.json (deflated 49%)\n",
      "  adding: kaggle/working/Finetuned_indicBERT_with_20000_sentences_2/model.safetensors (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r IndicBERTTuned_BatchSize8_weight_decay.zip /kaggle/working/Finetuned_indicBERT_with_20000_sentences_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:27:24.400673Z",
     "iopub.status.busy": "2024-03-12T19:27:24.400233Z",
     "iopub.status.idle": "2024-03-12T19:27:26.451700Z",
     "shell.execute_reply": "2024-03-12T19:27:26.450497Z",
     "shell.execute_reply.started": "2024-03-12T19:27:24.400639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/ (stored 0%)\n",
      "  adding: kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/tokenizer.json (deflated 77%)\n",
      "  adding: kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/tokenizer_config.json (deflated 74%)\n",
      "  adding: kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/special_tokens_map.json (deflated 49%)\n",
      "  adding: kaggle/working/tokenizer_indicBERT_with_20000_sentences_2/spiece.model (deflated 60%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r IndicBERT_tokenizer_BatchSize8_weight_decay.zip /kaggle/working/tokenizer_indicBERT_with_20000_sentences_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:43.874710Z",
     "iopub.status.busy": "2024-03-12T19:11:43.873805Z",
     "iopub.status.idle": "2024-03-12T19:11:44.649160Z",
     "shell.execute_reply": "2024-03-12T19:11:44.647654Z",
     "shell.execute_reply.started": "2024-03-12T19:11:43.874677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76c57299ff644bb887917cd9571be57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674c9c2037774b688abe320b45508712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df1b0726ef54f92b7c4525b6aefa9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #2:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f00950b4125451584dd51d40cef121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on test dataset #3:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = raw_datasets[\"test\"]\n",
    "tokenize_test_dataset = test_dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on test dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:11:52.490279Z",
     "iopub.status.busy": "2024-03-12T19:11:52.489875Z",
     "iopub.status.idle": "2024-03-12T19:12:10.220078Z",
     "shell.execute_reply": "2024-03-12T19:12:10.219016Z",
     "shell.execute_reply.started": "2024-03-12T19:11:52.490250Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, labels, metrics = trainer.predict(tokenize_test_dataset)\n",
    "\n",
    "lang_specific_results = {}\n",
    "for key in metrics:\n",
    "    if 'overall_precision' in key:\n",
    "      lang_specific_results['Precision'] = metrics[key]\n",
    "    elif 'overall_recall' in key:\n",
    "      lang_specific_results['Recall'] = metrics[key]\n",
    "    elif 'overall_f1' in key:\n",
    "      lang_specific_results['F1'] = metrics[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:12:15.935176Z",
     "iopub.status.busy": "2024-03-12T19:12:15.934553Z",
     "iopub.status.idle": "2024-03-12T19:12:15.942185Z",
     "shell.execute_reply": "2024-03-12T19:12:15.941125Z",
     "shell.execute_reply.started": "2024-03-12T19:12:15.935143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.23291881382465363, 'test_LOC_precision': 0.6650485436893204, 'test_LOC_recall': 0.6693811074918566, 'test_LOC_f1': 0.6672077922077922, 'test_LOC_number': 614, 'test_ORG_precision': 0.6104129263913824, 'test_ORG_recall': 0.6476190476190476, 'test_ORG_f1': 0.6284658040665435, 'test_ORG_number': 525, 'test_PER_precision': 0.7496855345911949, 'test_PER_recall': 0.7544303797468355, 'test_PER_f1': 0.7520504731861198, 'test_PER_number': 790, 'test_overall_precision': 0.6837563451776649, 'test_overall_recall': 0.6982892690513219, 'test_overall_f1': 0.6909463965119261, 'test_overall_accuracy': 0.9312823606293671, 'test_runtime': 17.7118, 'test_samples_per_second': 48.95, 'test_steps_per_second': 3.105}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:12:35.602078Z",
     "iopub.status.busy": "2024-03-12T19:12:35.601677Z",
     "iopub.status.idle": "2024-03-12T19:12:35.609777Z",
     "shell.execute_reply": "2024-03-12T19:12:35.608591Z",
     "shell.execute_reply.started": "2024-03-12T19:12:35.602046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro f1 score is :: 0.6909463965119261\n"
     ]
    }
   ],
   "source": [
    "print('macro f1 score is ::',metrics['test_overall_f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T11:36:41.984027Z",
     "iopub.status.busy": "2024-03-12T11:36:41.983649Z",
     "iopub.status.idle": "2024-03-12T11:36:41.993591Z",
     "shell.execute_reply": "2024-03-12T11:36:41.992546Z",
     "shell.execute_reply.started": "2024-03-12T11:36:41.983996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.25813451409339905, 'test_LOC_precision': 0.632890365448505, 'test_LOC_recall': 0.6205211726384365, 'test_LOC_f1': 0.6266447368421053, 'test_LOC_number': 614, 'test_ORG_precision': 0.5575868372943327, 'test_ORG_recall': 0.580952380952381, 'test_ORG_f1': 0.5690298507462687, 'test_ORG_number': 525, 'test_PER_precision': 0.7228915662650602, 'test_PER_recall': 0.6835443037974683, 'test_PER_f1': 0.7026675341574495, 'test_PER_number': 790, 'test_overall_precision': 0.6466244725738397, 'test_overall_recall': 0.6355624675997926, 'test_overall_f1': 0.6410457516339869, 'test_overall_accuracy': 0.9197205047001458, 'test_runtime': 17.3806, 'test_samples_per_second': 49.883, 'test_steps_per_second': 2.129}\n",
      "\n",
      " Macro f1 score:: 0.6327807072486078\n"
     ]
    }
   ],
   "source": [
    "# print(lang_specific_results)\n",
    "print(metrics)\n",
    "sum_of_f1_scores=metrics['test_LOC_f1']+metrics['test_ORG_f1']+metrics['test_PER_f1']\n",
    "macro_f1=sum_of_f1_scores/3\n",
    "print('\\n Macro f1 score::',macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:12:43.535606Z",
     "iopub.status.busy": "2024-03-12T19:12:43.534421Z",
     "iopub.status.idle": "2024-03-12T19:12:43.543795Z",
     "shell.execute_reply": "2024-03-12T19:12:43.542538Z",
     "shell.execute_reply.started": "2024-03-12T19:12:43.535559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.6837563451776649, 'Recall': 0.6982892690513219, 'F1': 0.6909463965119261}\n"
     ]
    }
   ],
   "source": [
    "print(lang_specific_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:15:21.234467Z",
     "iopub.status.busy": "2024-03-12T19:15:21.233700Z",
     "iopub.status.idle": "2024-03-12T19:21:52.903076Z",
     "shell.execute_reply": "2024-03-12T19:21:52.901830Z",
     "shell.execute_reply.started": "2024-03-12T19:15:21.234434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(train_dataset)\n",
    "\n",
    "lang_specific_results = {}\n",
    "for key in metrics:\n",
    "    if 'overall_precision' in key:\n",
    "      lang_specific_results['Precision'] = metrics[key]\n",
    "    elif 'overall_recall' in key:\n",
    "      lang_specific_results['Recall'] = metrics[key]\n",
    "    elif 'overall_f1' in key:\n",
    "      lang_specific_results['F1'] = metrics[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:22:44.578816Z",
     "iopub.status.busy": "2024-03-12T19:22:44.577791Z",
     "iopub.status.idle": "2024-03-12T19:22:44.587174Z",
     "shell.execute_reply": "2024-03-12T19:22:44.585868Z",
     "shell.execute_reply.started": "2024-03-12T19:22:44.578777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.13139191269874573, 'test_LOC_precision': 0.8311105328215471, 'test_LOC_recall': 0.8607910518159154, 'test_LOC_f1': 0.8456904541241891, 'test_LOC_number': 14841, 'test_ORG_precision': 0.7435542607428988, 'test_ORG_recall': 0.7249680443118875, 'test_ORG_f1': 0.734143535164677, 'test_ORG_number': 14082, 'test_PER_precision': 0.8521560574948666, 'test_PER_recall': 0.8505187652107083, 'test_PER_f1': 0.8513366241425733, 'test_PER_number': 15614, 'test_overall_precision': 0.8115474991607922, 'test_overall_recall': 0.8142443361699261, 'test_overall_f1': 0.812893680930712, 'test_overall_accuracy': 0.9609609810628628, 'test_runtime': 391.6528, 'test_samples_per_second': 51.066, 'test_steps_per_second': 3.192}\n",
      "\n",
      "\n",
      "{'Precision': 0.8115474991607922, 'Recall': 0.8142443361699261, 'F1': 0.812893680930712}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)\n",
    "print('\\n')\n",
    "print(lang_specific_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:12:47.494898Z",
     "iopub.status.busy": "2024-03-12T19:12:47.493842Z",
     "iopub.status.idle": "2024-03-12T19:12:47.509069Z",
     "shell.execute_reply": "2024-03-12T19:12:47.507729Z",
     "shell.execute_reply.started": "2024-03-12T19:12:47.494865Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def get_ner(sentence):\n",
    "    tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tok_sentence).logits.argmax(-1)\n",
    "        predicted_tokens_classes = [\n",
    "            model.config.id2label[t.item()] for t in logits[0]]\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        previous_token_id = 0\n",
    "        word_ids = tok_sentence.word_ids()\n",
    "        for word_index in range(len(word_ids)):\n",
    "            if word_ids[word_index] == None:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            elif word_ids[word_index] == previous_token_id:\n",
    "                previous_token_id = word_ids[word_index]\n",
    "            else:\n",
    "                predicted_labels.append(predicted_tokens_classes[word_index])\n",
    "                previous_token_id = word_ids[word_index]\n",
    "\n",
    "        ner_output = []\n",
    "        for index in range(len(sentence.split(' '))):\n",
    "            if(index<len(predicted_labels)):\n",
    "                ner_output.append((sentence.split(' ')[index], predicted_labels[index]))\n",
    "            else:\n",
    "                ner_output.append((sentence.split(' ')[index], 'O'))\n",
    "        return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T19:12:52.297621Z",
     "iopub.status.busy": "2024-03-12T19:12:52.297256Z",
     "iopub.status.idle": "2024-03-12T19:12:54.542653Z",
     "shell.execute_reply": "2024-03-12T19:12:54.541479Z",
     "shell.execute_reply.started": "2024-03-12T19:12:52.297595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'B-PER', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-LOC', 'NULL', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG'], ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['B-PER', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'NULL']]\n"
     ]
    }
   ],
   "source": [
    "All_sentences=['नारायण साईं पर जेल में रहते हुए पुलिस कर्मचारी को 13 करोड़ रुपए की रिश्वत देने का भी आरोप लगा था, लेकिन इस मामले में नारायण साईं को जमानत तो मिल चुकी है लेकिन रेप के मामले में अभी भी कोर्ट में सुनवाई चल रही है।',\n",
    "           'इसके बाद वह अपनी मां से तब तक विडियो कॉल पर बात करने से बचती रहीं तब तक उन्होंने अपने वेट कम नहीं कर लिया।',\n",
    "           'इससे पहले प्रिंस नरुला ने इस बात की पुष्टि की है कि वह शो की सहभागी एवं मोरक्को की सुंदरी नोरा फातेही के के साथ समय. . . दीप्ति अपहरण मामले पर बोले शाहरुख, लोग फिल्मों से गलत सीख लेते हैं',\n",
    "           'अखिलेश और राहुल पर हमला करते हुए योगी ने कहा कि शहजादे और युवराज का यूपी पर ध्यान नहीं जाता.',\n",
    "           'आषाढ़ माह में बारिश होने से तालाबों में मेढकाें की टर्र-टर्र सुनाई पड़ने लगती थी लेकिन इस बार बेल्हा से बादल इस कदर रूठे रहे कि मई और जून माह में सिर्फ एक मिलीमीटर बारिश हो सकी। बरसाती मेढक दिखे ही नहीं।',\n",
    "           'जानकारी है कि प्रशांत किशोर ने इस काम के लिए राहुल गांधी से कोई भी वेतन नहीं ले रहे हैं.',\n",
    "           'देवासुर संग्राम में शक्ति (नारी) ही चंडी-दुर्गा के रूप में प्रकट होती है।',\n",
    "           'इसका दुष्प्रभाव यह है कि जनप्रतिनिधियों से महत्वपूर्ण पार्टियां हो जाती हैं. फिर पार्टी कमान कंपनी का सीइओ हो जाता है और जनप्रतिनिधि उनके द्वारा नियुक्त होते हैं, केवल औपचारिक तौर पर उनका चुनाव जनता के द्वारा होना जरूरी है.',\n",
    "           'मुंबई: महाराष्ट्र की राजनीति में उठापटक का दौर जारी है.',\n",
    "           '20/08/2014 मुख्य अभियंता, धसान केन कछार सागर के अन्तर्गत गुण नियंत्रण के कार्यों को गति देने हेतु मुख्यालय परिवर्तन।',\n",
    "           'हालांकि, पिछले साल दिसंबर से सभी टेलिकॉम कंपनियों ने अपने प्रीपेड प्लान्स में बदलाव किया था, जिसके बाद ये प्रीपेड प्लान डिसकन्टिन्यू कर दिया गया है.',\n",
    "           'पैनासोनिक ने पेश किए दो स्‍मार्टफोन, कीमत है इनकी 27000 रुपए तक - India TV Paisa',\n",
    "           'एयर इंडिया को सरकार 2100 करोड़ रु की मदद देगी, 6 साल में 26000 करोड़ मिले फिर भी नहीं सुधरी हालत',\n",
    "           'पिछले मैच में हमारे साथ जो हुआ उससे टीम ने काफी कुछ सीखा.',\n",
    "           'सरकारें राजनीतिक दलों की होती हैं और वे जनता के हित में कोई योजना चलाते हैं, जिनमें वायदे ही तो होते हैं।',\n",
    "           'शपथ ग्रहण से पहले बीजेपी में बड़े बदलाव हो सकते हैं।',\n",
    "           'युधिष्ठिर की उदारता भी अलौकिक थी । जब कौरवो ने किसी प्रकार भी इनका राज्य लौटाना मंजूर नहीं किया तो इन्होंने केवल पांच गांव लेकर संतोष करना स्वीकार कर लिया और भगवान् श्रीकृष्णके द्वारा दुर्योधन को यह कहला भेजा कि यदि वह हमें हमारे इच्छानुसार केवल पांच गांव देना मंजूर कर ले तो हम युद्ध न करे ।',\n",
    "           'महंत ने कहा कि अब इंतजार के अलावा कोई विकल्प भी नहीं है।',\n",
    "           'गौरतलब है कि इस मंदिर के सामने की तरफ कुछ मीटर की दूरी पर ही पुलिस का नाका लगा रहता है।',\n",
    "           'इस शपथ ग्रहण समारोह में इस बार एक बात यह खास है कि पाकिस्‍तान के पीएम इमरान खान को न्‍योता नहीं दिया गया है।',\n",
    "           'इसी वजह से मिठाई की जगह पर लोगों ने उपहार देने के लिए ड्राई फ्रूट्स और चौकलेट का प्रयोग करना शुरू किया.',\n",
    "           'उनका कहना है कि प्रदर्शन के विश्लेषण के लिहाज से कम से कम 3-5 साल का नजरिया रखा जाना चाहिए।',\n",
    "           'रेंजर्स ने मशहूर पर्यटक स्थल टाफ्ट प्वाइंट से नीचे गुरुवार को दुर्गम इलाके से उनके शव बरामद किये। टाफ्ट प्वाइंट से योसेमिटी घाटी का मनोरम दृश्य देखने को मिलता है।',\n",
    "           'इसके पहले अपने बयान पर सफाई देते हुए प्रज्ञा सिंह ठाकुर ने ट्वीट किया, कभी-2 झूठ का बबण्डर इतना गहरा होता है कि दिन मे भी रात लगने लगती है किन्तु सूर्य अपना प्रकाश नहीं खोता पलभर के बबण्डर मे लोग भ्रमित न हों सूर्य का प्रकाश स्थाई है।',\n",
    "           'शायद हमें कभी ना पता चले लेकिन यह बहुत दुखद घटना है। खबर में बताया गया है कि दोनों 2014 से शादीशुदा थे और दोनों सॉफ्टवेयर इंजीनियर थे।'\n",
    "          ]\n",
    "IndicBERT_tag=[]\n",
    "for each_line in All_sentences:\n",
    "    # print(each_line)\n",
    "    output=get_ner(each_line)\n",
    "#     print(output)\n",
    "    List=[]\n",
    "    for index in range(len(output)):\n",
    "        List.append(output[index][1])\n",
    "        if output[index][0].find(\",\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\"।\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\".\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "        if output[index][0].find(\":\") != -1 and len(output[index][0])!=1:\n",
    "            List.append('NULL')\n",
    "#     print(List)\n",
    "    IndicBERT_tag.append(List)\n",
    "print(IndicBERT_tag)\n",
    "\n",
    "# for line in IndicBERT_tag:\n",
    "#     print(len(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
