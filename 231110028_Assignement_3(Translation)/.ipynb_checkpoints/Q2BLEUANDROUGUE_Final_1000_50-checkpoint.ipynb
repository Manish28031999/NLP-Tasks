{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwsYZ93zUVdd"
   },
   "source": [
    " # Distilled model of NLLB-200 with 600M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4IvX6tDH96q",
    "outputId": "20c81c61-e585-4d54-9eeb-afaf846246b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UE8EYZJNOJL",
    "outputId": "52e457e5-d2d2-4313-e430-b8a2ea7407d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for English to Hindi: {'rouge-1': {'r': 0.5902254416651604, 'p': 0.6094152341019763, 'f': 0.5959628237255723}, 'rouge-2': {'r': 0.3524832471274479, 'p': 0.3639016009324582, 'f': 0.3557903131408782}, 'rouge-l': {'r': 0.5528334603753297, 'p': 0.5711601794204133, 'f': 0.5584077229689641}}\n",
      "BLEU Score for English to Hindi: 0.6678217462523826\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__Hi_Text_Final.txt'\n",
    "translated_file = '/content/NLLB_En_to_hi_Text_Final.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for English to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for English to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6TwMFFB8YbD"
   },
   "source": [
    "For 50 sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl9r0NIp8RuB",
    "outputId": "88ff263c-3bf9-461e-c3ef-97ef19f86155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for English to Hindi for first 50 sentences: {'rouge-1': {'r': 0.5621031299912107, 'p': 0.5856226418039147, 'f': 0.5684212540825206}, 'rouge-2': {'r': 0.31922108969910146, 'p': 0.3310365024976102, 'f': 0.3212645390998109}, 'rouge-l': {'r': 0.519307454224482, 'p': 0.5409917788916555, 'f': 0.5248483723985778}}\n",
      "BLEU Score for English to Hindi for first 50 sentences: 0.6326001013892384\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for English to Hindi for first 50 sentences:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for English to Hindi for first 50 sentences:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jzk1cbl6KEMr",
    "outputId": "c7511495-24ed-48aa-8dd1-901870cc411c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to English: {'rouge-1': {'r': 0.6241465367240336, 'p': 0.6305206700862725, 'f': 0.6235661654598955}, 'rouge-2': {'r': 0.39438255160766467, 'p': 0.3963642366312159, 'f': 0.39267185550018474}, 'rouge-l': {'r': 0.5896449531397306, 'p': 0.5952201929636809, 'f': 0.5888811582765917}}\n",
      "BLEU Score for Hindi to English: 0.7134658592212416\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__En_Text_final.txt'\n",
    "translated_file = '/content/NLLB_Hi_to_En_Text_Final.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "\n",
    "\n",
    "# print(len(translated_sentences))\n",
    "# print(len(Groud_truth_Sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to English:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to English:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlgcfhe98vyy"
   },
   "source": [
    "For 50 sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3MTjHyi8ujT",
    "outputId": "705d8a3e-1434-4ae3-f1d1-ca6efa6e744d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to English For 50 sentences: {'rouge-1': {'r': 0.6266536284530294, 'p': 0.6183819690354077, 'f': 0.6159846413666255}, 'rouge-2': {'r': 0.37574502202304055, 'p': 0.3686356912603309, 'f': 0.36706443217311596}, 'rouge-l': {'r': 0.5781661109302447, 'p': 0.5704229184356302, 'f': 0.5678590736408582}}\n",
      "BLEU Score for Hindi to English For 50 sentences: 0.7084127840330927\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "# print(len(translated_sentences))\n",
    "# print(len(Groud_truth_Sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to English For 50 sentences:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to English For 50 sentences:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkRln8fIOJPE",
    "outputId": "71b38306-42fd-4786-ac87-775564da1245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to Gujarati: {'rouge-1': {'r': 0.4540202954021414, 'p': 0.47179618704309106, 'f': 0.4587490153398438}, 'rouge-2': {'r': 0.21326563394554746, 'p': 0.2212440435381612, 'f': 0.21573829626567065}, 'rouge-l': {'r': 0.44251007190915925, 'p': 0.45933738853166095, 'f': 0.4468207097273275}}\n",
      "BLEU Score for Hindi to Gujarati: 0.5935469377490841\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground_Gu_Text_Final.txt'\n",
    "translated_file = '/content/NLLB_Hi_To_GU_Text_Final.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "\n",
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to Gujarati:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to Gujarati:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtYt1cvZ9ZBc"
   },
   "source": [
    "For 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmKC9jpn86mJ",
    "outputId": "64dbc242-e9b9-4152-9cdd-17cf76c3612f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to Gujarati: {'rouge-1': {'r': 0.6266536284530294, 'p': 0.6183819690354077, 'f': 0.6159846413666255}, 'rouge-2': {'r': 0.37574502202304055, 'p': 0.3686356912603309, 'f': 0.36706443217311596}, 'rouge-l': {'r': 0.5781661109302447, 'p': 0.5704229184356302, 'f': 0.5678590736408582}}\n",
      "BLEU Score for Hindi to Gujarati: 0.7084127840330927\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to Gujarati:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to Gujarati:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbcWWFE4OxyZ",
    "outputId": "c5290eee-77de-44fe-fbc5-7194eba149fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Gujarati to Hindi: {'rouge-1': {'r': 0.5988166293988992, 'p': 0.6093416828530651, 'f': 0.6000056083308924}, 'rouge-2': {'r': 0.3703258231976582, 'p': 0.3755378456327351, 'f': 0.3703409199658835}, 'rouge-l': {'r': 0.5637704656729339, 'p': 0.573525536306012, 'f': 0.5648715126284934}}\n",
      "BLEU Score for Gujarati to Hindi: 0.6748789958024046\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__Hi_Text_Final.txt'\n",
    "translated_file = '/content/NLLB_GU_TO_HI_Text_Final.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Gujarati to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Gujarati to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkS8I6eY9zOG"
   },
   "source": [
    "For 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_wr2ce99ycc",
    "outputId": "76f2986a-80eb-495d-bee0-3927853340c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Gujarati to Hindi: {'rouge-1': {'r': 0.5648299060703088, 'p': 0.579161933037631, 'f': 0.5681033973320251}, 'rouge-2': {'r': 0.34778749941373455, 'p': 0.36297638176237257, 'f': 0.35150827954419206}, 'rouge-l': {'r': 0.5362368539956777, 'p': 0.5497318415432979, 'f': 0.5392362901841264}}\n",
      "BLEU Score for Gujarati to Hindi: 0.637911386529228\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Gujarati to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Gujarati to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNgKQk4-Ptxk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4A2DzCpP81g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iw1YhJpVB7K"
   },
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDgmPsRCP9Cx",
    "outputId": "6ea1db79-a520-4553-d8ed-8bf5403e042f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for English to Hindi: {'rouge-1': {'r': 0.5231192073377833, 'p': 0.5477349855508957, 'f': 0.5310940099789396}, 'rouge-2': {'r': 0.2843846723623814, 'p': 0.30163590914727195, 'f': 0.288422271310015}, 'rouge-l': {'r': 0.47779929898103285, 'p': 0.49927931904800504, 'f': 0.4844015487750677}}\n",
      "BLEU Score for English to Hindi: 0.5858068324060652\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/Hi_Ground_truth_chatgpt.txt'\n",
    "translated_file = '/content/En_to_hi_chatgpt.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for English to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for English to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnC8Cal4REuM",
    "outputId": "ecf1727f-87b8-44ed-d179-ca35bdb0e0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to English: {'rouge-1': {'r': 0.5824876743483554, 'p': 0.5823110514213455, 'f': 0.5763721499830524}, 'rouge-2': {'r': 0.33549023061561756, 'p': 0.3371779847259723, 'f': 0.33240857480095143}, 'rouge-l': {'r': 0.5342363946533417, 'p': 0.5326844266844266, 'f': 0.5278398136305649}}\n",
      "BLEU Score for Hindi to English: 0.671809350671886\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/En_Ground_truth_chatgpt.txt'\n",
    "translated_file = '/content/Hi_to_En_chatgpt.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to English:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to English:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMv7uZrCRU5X",
    "outputId": "1c6e8cb0-20be-4a8b-9da6-8c6a91785cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to Gujarati: {'rouge-1': {'r': 0.3024552752859041, 'p': 0.3103939399094198, 'f': 0.3025421049204379}, 'rouge-2': {'r': 0.11904843110106268, 'p': 0.12080180277239101, 'f': 0.11871187005222167}, 'rouge-l': {'r': 0.2950756434235136, 'p': 0.3035190566227718, 'f': 0.29544669974082227}}\n",
      "BLEU Score for Hindi to Gujarati: 0.4946657397317416\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/Gu_Ground_Truth_chatgpt.txt'\n",
    "translated_file = '/content/HitoGu_chatgpt.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to Gujarati:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to Gujarati:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq_FoLQvRe3u",
    "outputId": "91cd11aa-3321-4c2a-8bad-7c431e68b8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Gujarati to Hindi: {'rouge-1': {'r': 0.4674288251079275, 'p': 0.4780655632130975, 'f': 0.46883086449736566}, 'rouge-2': {'r': 0.2484641694585159, 'p': 0.25072484975651615, 'f': 0.2474670180172447}, 'rouge-l': {'r': 0.4478811503655159, 'p': 0.4580695037284852, 'f': 0.44921736815170554}}\n",
      "BLEU Score for Gujarati to Hindi: 0.5686468830187426\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/Hi_Ground_truth_chatgpt.txt'\n",
    "translated_file = '/content/Gutohi_chatgpt.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Gujarati to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Gujarati to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nlp4sbKU2LV"
   },
   "source": [
    "# Indic_Trans_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "th3fUyZ3TX8j",
    "outputId": "4cd83f35-39bf-4b14-beaa-3e5ecbf8dba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for English to Hindi: {'rouge-1': {'r': 0.6249445379717501, 'p': 0.6295938895888218, 'f': 0.6238687088198556}, 'rouge-2': {'r': 0.3910565999327303, 'p': 0.3936053099174017, 'f': 0.3902384750474276}, 'rouge-l': {'r': 0.5897472444656079, 'p': 0.5947721021790372, 'f': 0.5891143095234964}}\n",
      "BLEU Score for English to Hindi: 0.6996791099115457\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__Hi_Text_Final.txt'\n",
    "translated_file = '/content/IndicTrans_En_To_Hi_Final_1.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for English to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for English to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLVH0kDK_8Vk"
   },
   "source": [
    "For 50 Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zcb8qTSp_zpu",
    "outputId": "90df55aa-4f93-4e25-c23e-0c956017067e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for English to Hindi: {'rouge-1': {'r': 0.5768067168355094, 'p': 0.5912794308957523, 'f': 0.5782014791190354}, 'rouge-2': {'r': 0.33113260614140944, 'p': 0.33753097943971433, 'f': 0.3305598861064456}, 'rouge-l': {'r': 0.5456983347692328, 'p': 0.5598058326845379, 'f': 0.5470416683843335}}\n",
      "BLEU Score for English to Hindi: 0.650776666178536\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for English to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for English to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBUqIwyTTYEG",
    "outputId": "138191b0-4420-45a1-c129-acad3f50aada"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to English: {'rouge-1': {'r': 0.661844538640007, 'p': 0.6630589842002854, 'f': 0.6590469030038144}, 'rouge-2': {'r': 0.44818875393107976, 'p': 0.44542684742127514, 'f': 0.4442038912661666}, 'rouge-l': {'r': 0.6288293262035638, 'p': 0.6297424840952301, 'f': 0.6261075679047424}}\n",
      "BLEU Score for Hindi to English: 0.752517884350592\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__En_Text_final.txt'\n",
    "translated_file = '/content/IndicTrans_Hi_to_En_Final_1.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to English:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to English:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbHmnnFsAHEf"
   },
   "source": [
    "For 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9K20iOjABYf",
    "outputId": "526feb9f-6259-4722-889a-d3b415c613f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to English: {'rouge-1': {'r': 0.673333499945561, 'p': 0.6388986460138031, 'f': 0.649420545468417}, 'rouge-2': {'r': 0.437174937102801, 'p': 0.41343035744025725, 'f': 0.41925631924299184}, 'rouge-l': {'r': 0.6282948599985886, 'p': 0.596651345790059, 'f': 0.6060217745755607}}\n",
      "BLEU Score for Hindi to English: 0.719901501917833\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to English:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to English:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltC_vJsuTYF7",
    "outputId": "59d77752-1008-49a1-ff7f-303121af4a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to Gujarati: {'rouge-1': {'r': 0.4936869683542097, 'p': 0.49701724126168245, 'f': 0.49171064343587423}, 'rouge-2': {'r': 0.2484372991607599, 'p': 0.24865634810792034, 'f': 0.24656416993012797}, 'rouge-l': {'r': 0.46967418469706884, 'p': 0.4730798795704366, 'f': 0.4679207414867273}}\n",
      "BLEU Score for Hindi to Gujarati: 0.6354444268735525\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground_Gu_Text_Final.txt'\n",
    "translated_file = '/content/IndicTrans_Hi_to_Gu_Final_1.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to Gujarati:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to Gujarati:\", bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bObPy1csAS55"
   },
   "source": [
    "For 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Frg_my_fALe9",
    "outputId": "b1e1029c-72ed-4f40-a1bb-4f745b851e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Hindi to Gujarati: {'rouge-1': {'r': 0.4727457056128457, 'p': 0.46944968926249486, 'f': 0.46684830118289544}, 'rouge-2': {'r': 0.2420922146575771, 'p': 0.23668493589314024, 'f': 0.2364172105958085}, 'rouge-l': {'r': 0.4565016603860418, 'p': 0.4521926348226819, 'f': 0.45017378417988874}}\n",
      "BLEU Score for Hindi to Gujarati: 0.6086201270463817\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Hindi to Gujarati:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Hindi to Gujarati:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meVJHWhWTYJj",
    "outputId": "be2219f9-47a4-42dc-d081-ae398cb01047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Gujarati to Hindi: {'rouge-1': {'r': 0.5895216075253468, 'p': 0.5881777790290199, 'f': 0.5846658827440419}, 'rouge-2': {'r': 0.35494664296265044, 'p': 0.35400257724041095, 'f': 0.35189936837211905}, 'rouge-l': {'r': 0.5545758354596926, 'p': 0.5541255857975422, 'f': 0.5504956526063234}}\n",
      "BLEU Score for Gujarati to Hindi: 0.6721968393661957\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "def Read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentences = [line.strip() for line in f if line.strip()]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# File paths for reference and candidate sentences\n",
    "Groud_truth_file = '/content/NLLB_ground__Hi_Text_Final.txt'\n",
    "translated_file = '/content/IndicTrans_Gu_to_Hi_Final_1.txt'\n",
    "\n",
    "# Load sentences from files\n",
    "Groud_truth_Sentences = Read_file(Groud_truth_file)\n",
    "# print(len(Groud_truth_Sentences))\n",
    "translated_sentences = Read_file(translated_file)\n",
    "# print(len(translated_sentences))\n",
    "# Initialize ROUGE\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Gujarati to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Gujarati to Hindi:\", bleu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9hjc83xAb3D"
   },
   "source": [
    "For 50 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wn-2IvUHUjrF",
    "outputId": "6b66c17a-0325-4b1b-e67c-aa48276f7e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores for Gujarati to Hindi: {'rouge-1': {'r': 0.5656551499984939, 'p': 0.5803713294519638, 'f': 0.5681740647360676}, 'rouge-2': {'r': 0.33483569277748165, 'p': 0.35310934586727255, 'f': 0.33953148188628296}, 'rouge-l': {'r': 0.5329112747875908, 'p': 0.5497600937292318, 'f': 0.5367882356090864}}\n",
      "BLEU Score for Gujarati to Hindi: 0.6358255307440771\n"
     ]
    }
   ],
   "source": [
    "Groud_truth_Sentences=Groud_truth_Sentences[:50]\n",
    "translated_sentences=translated_sentences[:50]\n",
    "rouge = Rouge()\n",
    "rouge = Rouge()\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(translated_sentences,Groud_truth_Sentences, avg=True)\n",
    "print(\"ROUGE Scores for Gujarati to Hindi:\", scores)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[ref] for ref in Groud_truth_Sentences], translated_sentences)\n",
    "print(\"BLEU Score for Gujarati to Hindi:\", bleu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2O_gl9xAdke"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
