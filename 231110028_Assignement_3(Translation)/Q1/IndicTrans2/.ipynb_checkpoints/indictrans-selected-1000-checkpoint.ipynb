{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd /content/IndicTrans2/huggingface_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
    "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
    "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
    "!python3 -m pip install sentencepiece\n",
    "\n",
    "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
    "%cd IndicTransTokenizer\n",
    "!python3 -m pip install --editable ./\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After execution of first 3 block please restart the session and then execute from here onwards(don't reexecute first 3 cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:27:51.317838Z",
     "iopub.status.busy": "2024-04-17T10:27:51.317529Z",
     "iopub.status.idle": "2024-04-17T10:28:02.865296Z",
     "shell.execute_reply": "2024-04-17T10:28:02.864350Z",
     "shell.execute_reply.started": "2024-04-17T10:27:51.317813Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from IndicTransTokenizer import IndicProcessor, IndicTransTokenizer\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "quantization = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:28:09.798005Z",
     "iopub.status.busy": "2024-04-17T10:28:09.797482Z",
     "iopub.status.idle": "2024-04-17T10:28:09.810188Z",
     "shell.execute_reply": "2024-04-17T10:28:09.809252Z",
     "shell.execute_reply.started": "2024-04-17T10:28:09.797975Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
    "    if quantization == \"4-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    elif quantization == \"8-bit\":\n",
    "        qconfig = BitsAndBytesConfig(\n",
    "            load_in_8bit=True,\n",
    "            bnb_8bit_use_double_quant=True,\n",
    "            bnb_8bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "    else:\n",
    "        qconfig = None\n",
    "\n",
    "    tokenizer = IndicTransTokenizer(direction=direction)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        trust_remote_code=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        quantization_config=qconfig,\n",
    "    )\n",
    "\n",
    "    if qconfig == None:\n",
    "        model = model.to(DEVICE)\n",
    "        if DEVICE == \"cuda\":\n",
    "            model.half()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
    "    translations = []\n",
    "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
    "        batch = input_sentences[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Preprocess the batch and extract entity mappings\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize the batch and generate input encodings\n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            src=True,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Generate translations using the model\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode the generated tokens into text\n",
    "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
    "\n",
    "        # Postprocess the translations, including entity replacement\n",
    "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:28:15.456835Z",
     "iopub.status.busy": "2024-04-17T10:28:15.456455Z",
     "iopub.status.idle": "2024-04-17T10:28:26.891963Z",
     "shell.execute_reply": "2024-04-17T10:28:26.890898Z",
     "shell.execute_reply.started": "2024-04-17T10:28:15.456802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ac311fc4ec4b9ba964248acf4ffa32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51ceff1f28a47fcb922dfbf246b6e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f07c33fb14c83ab2a412b2d5c6ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a282595fda428da57ce9d0be93e320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7a6ed570714cffa5f9abcb66ea4b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eng_Latn - hin_Deva\n",
      "eng_Latn: When I was young, I used to go to the park every day.\n",
      "hin_Deva: जब मैं छोटा था, मैं हर दिन पार्क जाता था।\n",
      "eng_Latn: He has many old books, which he inherited from his ancestors.\n",
      "hin_Deva: उनके पास कई पुरानी किताबें हैं, जो उन्हें अपने पूर्वजों से विरासत में मिली हैं।\n"
     ]
    }
   ],
   "source": [
    "en_indic_ckpt_dir = \"ai4bharat/indictrans2-en-indic-dist-200M\"  # ai4bharat/indictrans2-en-indic-dist-200M\n",
    "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(en_indic_ckpt_dir, \"en-indic\", quantization)\n",
    "\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "en_sents = [\n",
    "    \"When I was young, I used to go to the park every day.\",\n",
    "    \"He has many old books, which he inherited from his ancestors.\",\n",
    "    \n",
    "]\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\n",
    "hi_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
    "\n",
    "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
    "for input_sentence, translation in zip(en_sents, hi_translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n",
    "\n",
    "# flush the models to free the GPU memory\n",
    "# del en_indic_tokenizer, en_indic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:28:31.104411Z",
     "iopub.status.busy": "2024-04-17T10:28:31.103875Z",
     "iopub.status.idle": "2024-04-17T10:28:31.608737Z",
     "shell.execute_reply": "2024-04-17T10:28:31.607868Z",
     "shell.execute_reply.started": "2024-04-17T10:28:31.104381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "eng_Latn - hin_Deva\n",
      "eng_Latn: The Prime Minister said that the Government is working on various schemes with clear objectives and time limits.\n",
      "hin_Deva: प्रधानमंत्री ने कहा कि सरकार स्पष्ट उद्देश्यों और समय सीमा के साथ विभिन्न योजनाओं पर काम कर रही है।\n"
     ]
    }
   ],
   "source": [
    "en_sents = [\n",
    "    \"The Prime Minister said that the Government is working on various schemes with clear objectives and time limits.\",\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "src_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\n",
    "hi_translations = batch_translate(en_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)\n",
    "\n",
    "print(f\"\\n{src_lang} - {tgt_lang}\")\n",
    "for input_sentence, translation in zip(en_sents, hi_translations):\n",
    "    print(f\"{src_lang}: {input_sentence}\")\n",
    "    print(f\"{tgt_lang}: {translation}\")\n",
    "\n",
    "# flush the models to free the GPU memory\n",
    "# del en_indic_tokenizer, en_indic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:33:51.820929Z",
     "iopub.status.busy": "2024-04-17T10:33:51.820171Z",
     "iopub.status.idle": "2024-04-17T10:33:51.872520Z",
     "shell.execute_reply": "2024-04-17T10:33:51.871599Z",
     "shell.execute_reply.started": "2024-04-17T10:33:51.820894Z"
    }
   },
   "outputs": [],
   "source": [
    "#please specify the file path correctly here \n",
    "#here we are loading the same 1000 lines which are taken in NLLB model\n",
    "\n",
    "with open(\"/kaggle/input/selected1000/NLLB_ground__En_Text_final.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_en = f.readlines()\n",
    "\n",
    "with open(\"/kaggle/input/selected1000/NLLB_ground_Gu_Text_Final.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_gu = f.readlines()\n",
    "    \n",
    "with open(\"/kaggle/input/selected1000/NLLB_ground__Hi_Text_Final.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_hi = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:36:29.340563Z",
     "iopub.status.busy": "2024-04-17T10:36:29.339697Z",
     "iopub.status.idle": "2024-04-17T10:39:33.455608Z",
     "shell.execute_reply": "2024-04-17T10:39:33.454740Z",
     "shell.execute_reply.started": "2024-04-17T10:36:29.340525Z"
    }
   },
   "outputs": [],
   "source": [
    "src_lang, tgt_lang = \"eng_Latn\", \"hin_Deva\"\n",
    "hindi_translations = batch_translate(test_en, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:39:33.457590Z",
     "iopub.status.busy": "2024-04-17T10:39:33.457291Z",
     "iopub.status.idle": "2024-04-17T10:39:33.464394Z",
     "shell.execute_reply": "2024-04-17T10:39:33.463412Z",
     "shell.execute_reply.started": "2024-04-17T10:39:33.457564Z"
    }
   },
   "outputs": [],
   "source": [
    "# File path to save the text file\n",
    "txt_file3 = 'IndicTrans_En_To_Hi_Final_1.txt'\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open(txt_file3, mode='w', encoding='utf-8') as file:\n",
    "    # Write each sentence to the text file\n",
    "    for sentence in hindi_translations:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:39:33.465754Z",
     "iopub.status.busy": "2024-04-17T10:39:33.465450Z",
     "iopub.status.idle": "2024-04-17T10:39:33.522697Z",
     "shell.execute_reply": "2024-04-17T10:39:33.521720Z",
     "shell.execute_reply.started": "2024-04-17T10:39:33.465730Z"
    }
   },
   "outputs": [],
   "source": [
    "del en_indic_tokenizer, en_indic_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi To English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:42:39.487230Z",
     "iopub.status.busy": "2024-04-17T10:42:39.486316Z",
     "iopub.status.idle": "2024-04-17T10:42:41.170232Z",
     "shell.execute_reply": "2024-04-17T10:42:41.169015Z",
     "shell.execute_reply.started": "2024-04-17T10:42:39.487192Z"
    }
   },
   "outputs": [],
   "source": [
    "indic_en_ckpt_dir = \"ai4bharat/indictrans2-indic-en-dist-200M\"  # ai4bharat/indictrans2-indic-en-dist-200M\n",
    "indic_en_tokenizer, indic_en_model = initialize_model_and_tokenizer(indic_en_ckpt_dir, \"indic-en\", \"\")\n",
    "\n",
    "ip = IndicProcessor(inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:42:48.139835Z",
     "iopub.status.busy": "2024-04-17T10:42:48.139101Z",
     "iopub.status.idle": "2024-04-17T10:45:36.296359Z",
     "shell.execute_reply": "2024-04-17T10:45:36.295451Z",
     "shell.execute_reply.started": "2024-04-17T10:42:48.139805Z"
    }
   },
   "outputs": [],
   "source": [
    "src_lang, tgt_lang = \"hin_Deva\", \"eng_Latn\"\n",
    "english_translations = batch_translate(test_hi, src_lang, tgt_lang, indic_en_model, indic_en_tokenizer, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:45:36.298394Z",
     "iopub.status.busy": "2024-04-17T10:45:36.298086Z",
     "iopub.status.idle": "2024-04-17T10:45:36.304295Z",
     "shell.execute_reply": "2024-04-17T10:45:36.303567Z",
     "shell.execute_reply.started": "2024-04-17T10:45:36.298367Z"
    }
   },
   "outputs": [],
   "source": [
    "# File path to save the text file\n",
    "txt_file2 = 'IndicTrans_Hi_to_En_Final_1.txt'\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open(txt_file2, mode='w', encoding='utf-8') as file:\n",
    "    # Write each sentence to the text file\n",
    "    for sentence in english_translations:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:45:36.305684Z",
     "iopub.status.busy": "2024-04-17T10:45:36.305358Z",
     "iopub.status.idle": "2024-04-17T10:45:36.359799Z",
     "shell.execute_reply": "2024-04-17T10:45:36.358995Z",
     "shell.execute_reply.started": "2024-04-17T10:45:36.305650Z"
    }
   },
   "outputs": [],
   "source": [
    "del indic_en_tokenizer, indic_en_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindi to Gujarati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:45:36.362885Z",
     "iopub.status.busy": "2024-04-17T10:45:36.362558Z",
     "iopub.status.idle": "2024-04-17T10:45:45.430633Z",
     "shell.execute_reply": "2024-04-17T10:45:45.429823Z",
     "shell.execute_reply.started": "2024-04-17T10:45:36.362842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021726add72b4fc39286e9a973dd7a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a2f00c80564cdea1bae0fbd2684bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_indictrans.py:   0%|          | 0.00/14.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- configuration_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c017d6c95aaa42d0a5cabd1c0e27096a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_indictrans.py:   0%|          | 0.00/61.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n",
      "- modeling_indictrans.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7794e5f16bb84a18aea520489d4c14fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a1280c66b248919529e57246b5f780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indic_indic_ckpt_dir = \"ai4bharat/indictrans2-indic-indic-dist-320M\"  # ai4bharat/indictrans2-indic-indic-dist-320M\n",
    "indic_indic_tokenizer, indic_indic_model = initialize_model_and_tokenizer(indic_indic_ckpt_dir, \"indic-indic\", quantization)\n",
    "\n",
    "ip = IndicProcessor(inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:45:45.431999Z",
     "iopub.status.busy": "2024-04-17T10:45:45.431688Z",
     "iopub.status.idle": "2024-04-17T10:48:45.640042Z",
     "shell.execute_reply": "2024-04-17T10:48:45.639101Z",
     "shell.execute_reply.started": "2024-04-17T10:45:45.431973Z"
    }
   },
   "outputs": [],
   "source": [
    "src_lang, tgt_lang = \"hin_Deva\", \"guj_Gujr\"\n",
    "Gujrati_translations = batch_translate(test_hi, src_lang, tgt_lang, indic_indic_model, indic_indic_tokenizer, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:48:45.641678Z",
     "iopub.status.busy": "2024-04-17T10:48:45.641374Z",
     "iopub.status.idle": "2024-04-17T10:48:45.648045Z",
     "shell.execute_reply": "2024-04-17T10:48:45.647262Z",
     "shell.execute_reply.started": "2024-04-17T10:48:45.641652Z"
    }
   },
   "outputs": [],
   "source": [
    "# File path to save the text file\n",
    "txt_file2 = 'IndicTrans_Hi_to_Gu_Final_1.txt'\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open(txt_file2, mode='w', encoding='utf-8') as file:\n",
    "    # Write each sentence to the text file\n",
    "    for sentence in Gujrati_translations:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gujarati to Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:48:45.649437Z",
     "iopub.status.busy": "2024-04-17T10:48:45.649158Z",
     "iopub.status.idle": "2024-04-17T10:51:51.736252Z",
     "shell.execute_reply": "2024-04-17T10:51:51.735326Z",
     "shell.execute_reply.started": "2024-04-17T10:48:45.649415Z"
    }
   },
   "outputs": [],
   "source": [
    "src_lang, tgt_lang =  \"guj_Gujr\",\"hin_Deva\"\n",
    "Hindi_translations_from_gujarati = batch_translate(test_gu, src_lang, tgt_lang, indic_indic_model, indic_indic_tokenizer, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-17T10:51:51.737982Z",
     "iopub.status.busy": "2024-04-17T10:51:51.737641Z",
     "iopub.status.idle": "2024-04-17T10:51:51.744797Z",
     "shell.execute_reply": "2024-04-17T10:51:51.744033Z",
     "shell.execute_reply.started": "2024-04-17T10:51:51.737955Z"
    }
   },
   "outputs": [],
   "source": [
    "# File path to save the text file\n",
    "txt_file1 = 'IndicTrans_Gu_to_Hi_Final_1.txt'\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open(txt_file1, mode='w', encoding='utf-8') as file:\n",
    "    # Write each sentence to the text file\n",
    "    for sentence in Hindi_translations_from_gujarati:\n",
    "        file.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4808027,
     "sourceId": 8134001,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4816402,
     "sourceId": 8145107,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
