{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f3fa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce45eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_unicode=[]\n",
    "All_syllables=[]\n",
    "All_bigram_characters=[]\n",
    "All_bigram_syllables=[]\n",
    "global_frequency_map = {}\n",
    "global_syllable_frequency_map = {}\n",
    "global_bigram_frequency_map = {}\n",
    "global_bigram_syllable_frequency_map = {}\n",
    "def correct(text):\n",
    "   # List representing the actual forms of Hindi matras\n",
    "    actual_matras = ['ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ै', 'ो', 'ौ', 'ृ', 'ॅ', 'ॉ', 'ं', 'ः', 'ँ']\n",
    "\n",
    "# List representing the original forms of Hindi matras\n",
    "    original_matras = ['आ', 'इ', 'ई', 'उ', 'ऊ', 'ए', 'ऐ', 'ओ', 'औ', 'ऋ', 'ॲ', 'ऑ', 'अं', 'अ:', 'अँ']\n",
    "\n",
    "# Create a dictionary mapping from actual form to original form\n",
    "    matras_mapping = dict(zip(actual_matras, original_matras))\n",
    "    unicode=[]\n",
    "    bigram=[]\n",
    "    syllables=[]\n",
    "    bigram_syllables=[]\n",
    "    hindi_punctuation_marks = ['।', '?', '!', ',', ';', '‘', '’', '(', ')']\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in hindi_punctuation_marks:\n",
    "            continue\n",
    "        \n",
    "        if text[i] in original_matras or text[i]=='अ':\n",
    "            unicode.append(text[i])\n",
    "#             print(text[i])\n",
    "        elif text[i] in actual_matras:\n",
    "            original_form = matras_mapping.get(text[i], text[i])  # Use get method to handle cases where actual form not found\n",
    "            unicode.append(original_form)\n",
    "#             print(original_form)\n",
    "        elif text[i]=='्':\n",
    "            continue\n",
    "        else:\n",
    "            if i+1<len(text) and text[i+1] not in actual_matras and text[i+1]!='्':\n",
    "                tmp=text[i]+'्'\n",
    "#                 print(tmp)\n",
    "#                 print('अ')\n",
    "                unicode.append(tmp)\n",
    "                unicode.append('अ')\n",
    "                \n",
    "            else:\n",
    "                tmp=text[i]+'्'\n",
    "#                 print(tmp)\n",
    "                unicode.append(tmp)\n",
    "    if text[len(text)-1] not in actual_matras  and text[len(text)-1] not in original_matras and text[len(text)-1]!='।':\n",
    "#         print('अ')\n",
    "        unicode.append('अ')\n",
    "#     print(unicode)\n",
    "    All_unicode.append(unicode)\n",
    "    matras_reverse_mapping = dict(zip(original_matras,actual_matras))\n",
    "    sy=\"\"\n",
    "    first_letter=1\n",
    "    for i in range(len(unicode)):\n",
    "#         print(i)\n",
    "        if unicode[i] in original_matras or unicode[i]=='अ':\n",
    "            if first_letter==1:\n",
    "                sy=sy+unicode[i]\n",
    "                syllables.append(sy)\n",
    "                sy=\"\"\n",
    "                first_letter=0\n",
    "            else:\n",
    "                if unicode[i]!='अ' and sy!=\"\":\n",
    "                    correct_matra=matras_reverse_mapping.get(unicode[i], unicode[i])\n",
    "                    sy=sy+correct_matra\n",
    "                elif sy==\"\":\n",
    "                    sy=sy+unicode[i]\n",
    "                syllables.append(sy)\n",
    "                sy=\"\"\n",
    "                first_letter=0\n",
    "                \n",
    "        else:\n",
    "            if i+1<len(unicode) and (unicode[i+1] in original_matras or unicode[i+1]=='अ'):\n",
    "                t=unicode[i].replace('्', '')\n",
    "                sy=sy+t\n",
    "            else:\n",
    "                sy=sy+unicode[i]\n",
    "            first_letter=0\n",
    "#     print(syllables)\n",
    "    All_syllables.append(syllables)\n",
    "    \n",
    "        \n",
    "        \n",
    "     \n",
    "    \n",
    "    for i in range(len(unicode) - 1):\n",
    "        combined_character = unicode[i] + unicode[i+1]\n",
    "        bigram.append(combined_character)\n",
    "        \n",
    "    for i in range(len(syllables) - 1):\n",
    "        combined_character = syllables[i] + syllables[i+1]\n",
    "        bigram_syllables.append(combined_character)\n",
    "    All_bigram_characters.append(bigram)\n",
    "    All_bigram_syllables.append(bigram_syllables)\n",
    "#     print(bigram)\n",
    "#     print(bigram_syllables)\n",
    "    \n",
    "    \n",
    "    global global_frequency_map\n",
    "    global global_bigram_frequency_map\n",
    "    global global_syllable_frequency_map\n",
    "    global global_bigram_syllable_frequency_map\n",
    "    \n",
    "    for i in syllables:\n",
    "        global_syllable_frequency_map[i] = global_syllable_frequency_map.get(i, 0) + 1\n",
    "        \n",
    "    for i in unicode:\n",
    "        global_frequency_map[i] = global_frequency_map.get(i, 0) + 1\n",
    "    \n",
    "    for i in bigram:\n",
    "        global_bigram_frequency_map[i] = global_bigram_frequency_map.get(i, 0) + 1\n",
    "    \n",
    "    for i in bigram_syllables:\n",
    "        global_bigram_syllable_frequency_map[i] = global_bigram_syllable_frequency_map.get(i, 0) + 1\n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649d952d-329c-45db-a833-42e8a4f8bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Character Frequency Map:\n",
      "अ-> 7196331\n",
      "आ-> 2991109\n",
      "ए-> 2318442\n",
      "क्-> 2219964\n",
      "र्-> 2115649\n",
      "ई-> 1460305\n",
      "इ-> 1432973\n",
      "न्-> 1334448\n",
      "स्-> 1283708\n",
      "अं-> 1201207\n",
      "ह्-> 1133159\n",
      "म्-> 1053237\n",
      "त्-> 980066\n",
      "ल्-> 919917\n",
      "ओ-> 896588\n",
      "प्-> 805896\n",
      "य्-> 752819\n",
      "व्-> 624743\n",
      "द्-> 607633\n",
      "उ-> 587149\n",
      "Sorted bigram Frequency Map:\n",
      "र्अ-> 1170914\n",
      "अर्-> 785426\n",
      "क्अ-> 612989\n",
      "स्अ-> 522329\n",
      "न्अ-> 517445\n",
      "अन्-> 432317\n",
      "क्ए-> 407130\n",
      "प्अ-> 404423\n",
      "अह्-> 390173\n",
      "आर्-> 368512\n",
      "एअं-> 359377\n",
      "त्अ-> 354940\n",
      "अक्-> 350040\n",
      "ल्अ-> 330917\n",
      "न्ए-> 328953\n",
      "म्अ-> 323812\n",
      "क्आ-> 314321\n",
      "अत्-> 308471\n",
      "य्आ-> 297778\n",
      "ह्ऐ-> 297199\n",
      "Sorted syllable Global Frequency Map:\n",
      "र-> 1007237\n",
      "अं-> 989009\n",
      "क-> 601021\n",
      "न-> 506708\n",
      "स-> 493450\n",
      "के-> 405005\n",
      "प-> 390618\n",
      "ने-> 328102\n",
      "ल-> 327479\n",
      "त-> 309793\n",
      "का-> 307965\n",
      "है-> 297019\n",
      "म-> 293077\n",
      "मे-> 292706\n",
      "ए-> 288665\n",
      "ह-> 278578\n",
      "अ-> 253552\n",
      "ब-> 243252\n",
      "की-> 235320\n",
      "ग-> 226185\n",
      "Sorted bigram syllable Global Frequency Map:\n",
      "मेअं-> 259224\n",
      "कर-> 160040\n",
      "और-> 115671\n",
      "पर-> 99662\n",
      "इस-> 82883\n",
      "हैअं-> 80715\n",
      "हीअं-> 55632\n",
      "एक-> 54571\n",
      "लिए-> 54024\n",
      "नही-> 49367\n",
      "अप-> 45143\n",
      "कार-> 39111\n",
      "किया-> 37430\n",
      "योअं-> 34861\n",
      "रने-> 34496\n",
      "कहा-> 33135\n",
      "यह-> 31400\n",
      "गया-> 30280\n",
      "सर-> 30116\n",
      "उन-> 29754\n"
     ]
    }
   ],
   "source": [
    "def extract_words(text):\n",
    "    \n",
    "    # Define a regular expression pattern to match Hindi words\n",
    "    # This pattern matches sequences of Hindi characters (Unicode range for Hindi script)\n",
    "    pattern = r'[\\u0900-\\u097F]+'\n",
    "    \n",
    "    # Find all matches of the pattern in the text\n",
    "    words = re.findall(pattern, text)\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "#specify the file path as first argument \n",
    "with open('hi_100_1.txt', 'r', encoding='utf-8') as file:\n",
    "        corpus = file.read()\n",
    "words = extract_words(corpus)\n",
    "for word in words:\n",
    "#     print(\"Extracted words:\", word)\n",
    "    correct(word)\n",
    "\n",
    "\n",
    "#stored all charcters frequency in sorted order\n",
    "sorted_frequency_map = sorted(global_frequency_map.items(), key=lambda item: item[1], reverse=True)\n",
    "#stored all bigram charcters frequency in sorted order\n",
    "sorted_bigram_frequency_map = sorted(global_bigram_frequency_map.items(), key=lambda item: item[1], reverse=True)\n",
    "#stored all syllables frequency in sorted order\n",
    "sorted_syllable_frequency_map = sorted(global_syllable_frequency_map.items(), key=lambda item: item[1], reverse=True)\n",
    "#stored all bigram syllables frequency in sorted order\n",
    "sorted_bigram_syllable_frequency_map = sorted(global_bigram_syllable_frequency_map.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# I have commented for all print Statements if you want to see charaters,syllables,bigram charcaters ,bigram syllables then uncomment accordingly.\n",
    "# print(\"Corrected Unicode word wise\")\n",
    "# print(All_unicode)\n",
    "# print(\"Bigram Characters word wise\")\n",
    "# print(All_bigram_characters)\n",
    "# print(\"Syllables word wise\" )\n",
    "# print(All_syllables)\n",
    "# print(\"Bigram Syllables word wise\")\n",
    "# print(All_bigram_syllables)\n",
    "\n",
    "#print top 20 characters\n",
    "print(\"Sorted Character Frequency Map:\")\n",
    "for word, frequency in sorted_frequency_map[:20]:\n",
    "    print(f\"{word}-> {frequency}\")\n",
    "#print top 20 bigram characters\n",
    "print(\"Sorted bigram Frequency Map:\")\n",
    "for word, frequency in sorted_bigram_frequency_map[:20]:\n",
    "    print(f\"{word}-> {frequency}\")\n",
    "#print top 20 syllables\n",
    "print(\"Sorted syllable Global Frequency Map:\")\n",
    "for word, frequency in sorted_syllable_frequency_map[:20]:\n",
    "    print(f\"{word}-> {frequency}\")\n",
    "#print top 20 bigram syllables\n",
    "print(\"Sorted bigram syllable Global Frequency Map:\")\n",
    "for word, frequency in sorted_bigram_syllable_frequency_map[:20]:\n",
    "    print(f\"{word}-> {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421cc80-3be8-4d80-a37d-80c24936d695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
